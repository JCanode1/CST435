{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Application: Sentimental Analysis on Steam Reviews (Possibly?)\n",
    "\n",
    "## Team\n",
    "\n",
    "* Gabriel Aracena\n",
    "* Joshua Canode\n",
    "* Aaron Galicia\n",
    "\n",
    "### Project Description\n",
    "\n",
    "A key area of knowledge in data analytics is the ability to extract meaning from text. This assignment provides the foundational skills in this area by detecting whether a text conveys a positive or negative message.\n",
    "\n",
    "Analyze the sentiment (e.g., negative, neutral, positive) conveyed in a large body (corpus) of texts using the NLTK package in Python. Complete the steps below. Then, write a comprehensive technical report as a Python Jupyter notebook to include all code, code comments, all outputs, plots, and analysis. Make sure the project documentation contains a) Problem statement, b) Algorithm of the solution, c) Analysis of the findings, and d) References.\n",
    "\n",
    "## Abstract\n",
    "\n",
    "TODO\n",
    "\n",
    "### Data Preparation:\n",
    "\n",
    "TODO\n",
    "\n",
    "### ANN Model Building:\n",
    "\n",
    "TODO\n",
    "\n",
    "\n",
    "### Training the ANN:\n",
    "\n",
    "\n",
    "\n",
    "### Evaluation:\n",
    "\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "\n",
    "## Interpretation and Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app_id        app_name                                        review_text  \\\n",
      "0      10  Counter-Strike                                    Ruined my life.   \n",
      "1      10  Counter-Strike  This will be more of a ''my experience with th...   \n",
      "2      10  Counter-Strike                      This game saved my virginity.   \n",
      "3      10  Counter-Strike  • Do you like original games? • Do you like ga...   \n",
      "4      10  Counter-Strike           Easy to learn, hard to master.             \n",
      "\n",
      "   review_score  review_votes  \n",
      "0             1             0  \n",
      "1             1             1  \n",
      "2             1             0  \n",
      "3             1             0  \n",
      "4             1             1  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327   Best bowling simulator 2014 10/10 It has good ...             1   \n",
      "1662500  Marvel characters? Check. Tons of loot? Check....             1   \n",
      "2061157  This game while its not the original is defina...             1   \n",
      "1171799  This game ♥♥♥♥ing awesome ,You can be professi...             1   \n",
      "1450080  If you are high, play this game. 420/420 would...             1   \n",
      "\n",
      "         review_votes  \n",
      "301327              1  \n",
      "1662500             0  \n",
      "2061157             0  \n",
      "1171799             0  \n",
      "1450080             0  \n",
      "(64171, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sampling the dataset to decrease run time\n",
    "sample_size = int(0.01 * len(df))\n",
    "reduced_sample = df.sample(n=sample_size, random_state=42) \n",
    "print(reduced_sample.head())\n",
    "\n",
    "print(reduced_sample.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "# Specify the NLTK data path explicitly\n",
    "nltk.data.path.append('C:/Users/josh/nltk_data')  # Replace with the actual path to your nltk_data directory\n",
    "\n",
    "# Download the required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_lower(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return text\n",
    "\n",
    "# tokenize the text\n",
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "        cleaned_text = \" \".join(tokens)\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    if isinstance(text, str):\n",
    "        # Removing Punctuation\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in string.punctuation]\n",
    "        cleaned_text = \" \".join(tokens)\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Stop Word Removal\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        cleaned_text = \" \".join(filtered_tokens)\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "import re\n",
    "# handleing things like 10/10\n",
    "def replace_good_ratings(text):\n",
    "    pattern = r'(\\d+)/(\\d+)'\n",
    "\n",
    "    def replace(match):\n",
    "        numerator = int(match.group(1))\n",
    "        denominator = int(match.group(2))\n",
    "\n",
    "        # Check if the numerator is not 0\n",
    "        if numerator != 0:\n",
    "            return 'great'\n",
    "        else:\n",
    "            return 'very bad'  # Replace \"0/number\" with \"very bad\"\n",
    "\n",
    "    cleaned_text = re.sub(pattern, replace, text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case the text\n",
    "reduced_sample['review_text'] = df['review_text'].apply(preprocess_text_lower)\n",
    "# 6 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(tokenize_text)\n",
    "# 24 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(remove_punctuation)\n",
    "# 31 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(remove_stopwords)\n",
    "# 50 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace good ratings\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(replace_good_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327    best bowling simulator 2014 great good storyline             1   \n",
      "1662500  marvel characters check tons loot check tons c...             1   \n",
      "2061157  game original definately one best renditions p...             1   \n",
      "1171799  game ♥♥♥♥ing awesome professional heister fun ...             1   \n",
      "1450080                    high play game great would dank             1   \n",
      "\n",
      "         review_votes  \n",
      "301327              1  \n",
      "1662500             0  \n",
      "2061157             0  \n",
      "1171799             0  \n",
      "1450080             0  \n"
     ]
    }
   ],
   "source": [
    "# Print the result (original and cleaned text for the first few rows)\n",
    "print(reduced_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64171, 5)\n",
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327    best bowling simulator 2014 great good storyline             1   \n",
      "1662500  marvel characters check tons loot check tons c...             1   \n",
      "2061157  game original definately one best renditions p...             1   \n",
      "1171799  game ♥♥♥♥ing awesome professional heister fun ...             1   \n",
      "1450080                    high play game great would dank             1   \n",
      "\n",
      "         review_votes  sentiment_scores  \n",
      "301327              1          0.000461  \n",
      "1662500             0          0.000660  \n",
      "2061157             0          0.000735  \n",
      "1171799             0          0.000597  \n",
      "1450080             0          0.000420  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "print(reduced_sample.shape)\n",
    "\n",
    "# 1. TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust the number of features as needed\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(reduced_sample['review_text'])\n",
    "tfidf_matrix = csr_matrix(tfidf_matrix)\n",
    "\n",
    "# 2. Calculate Sentiment Scores in Batches and Append to DataFrame\n",
    "batch_size = 1000  # Number of rows to process in each batch\n",
    "sentiment_scores = []\n",
    "\n",
    "for start in range(0, len(reduced_sample), batch_size):\n",
    "    end = min(start + batch_size, len(reduced_sample))\n",
    "    batch_tfidf_matrix = tfidf_matrix[start:end]\n",
    "    batch_scores = batch_tfidf_matrix.mean(axis=1)\n",
    "    sentiment_scores.extend(batch_scores)\n",
    "\n",
    "# Add the 'sentiment_scores' column to 'reduced_sample' from the TF-IDF scores\n",
    "reduced_sample['sentiment_scores'] = sentiment_scores\n",
    "\n",
    "\n",
    "# slopy very bad code... \n",
    "def extract_sentiment_score(scores):\n",
    "    try:\n",
    "        return float(scores[0][0][0][0])\n",
    "    except (IndexError, ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "reduced_sample['sentiment_scores'] = reduced_sample['sentiment_scores'].apply(extract_sentiment_score)\n",
    "\n",
    "\n",
    "# Print the result\n",
    "print(reduced_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327    best bowling simulator 2014 great good storyline             1   \n",
      "1662500  marvel characters check tons loot check tons c...             1   \n",
      "2061157  game original definately one best renditions p...             1   \n",
      "1171799  game ♥♥♥♥ing awesome professional heister fun ...             1   \n",
      "1450080                    high play game great would dank             1   \n",
      "\n",
      "         review_votes  sentiment_scores  vader_sentiment_score  \n",
      "301327              1          0.000461                 0.9042  \n",
      "1662500             0          0.000660                 0.9674  \n",
      "2061157             0          0.000735                 0.8516  \n",
      "1171799             0          0.000597                 0.9460  \n",
      "1450080             0          0.000420                 0.7579  \n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize Vader sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to calculate sentiment score\n",
    "def calculate_sentiment_score(review):\n",
    "    sentiment_dict = sia.polarity_scores(review)\n",
    "    return sentiment_dict['compound']\n",
    "\n",
    "# Calculate sentiment scores for each review\n",
    "reduced_sample['vader_sentiment_score'] = reduced_sample['review_text'].apply(calculate_sentiment_score)\n",
    "\n",
    "# Print the result\n",
    "print(reduced_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327    best bowling simulator 2014 great good storyline             1   \n",
      "1662500  marvel characters check tons loot check tons c...             1   \n",
      "2061157  game original definately one best renditions p...             1   \n",
      "1171799  game ♥♥♥♥ing awesome professional heister fun ...             1   \n",
      "1450080                    high play game great would dank             1   \n",
      "\n",
      "         review_votes  sentiment_scores  vader_sentiment_score  \\\n",
      "301327              1          0.000461                 0.9042   \n",
      "1662500             0          0.000660                 0.9674   \n",
      "2061157             0          0.000735                 0.8516   \n",
      "1171799             0          0.000597                 0.9460   \n",
      "1450080             0          0.000420                 0.7579   \n",
      "\n",
      "                                     word_sentiment_scores  \n",
      "301327                 [3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0]  \n",
      "1662500  [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2061157  [0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1171799  [0.0, 0.0, 4.0, 0.0, 0.0, 4.0, 0.0, 1.0, 4.0, ...  \n",
      "1450080                     [0.0, 0.0, 0.0, 3.0, 0.0, 0.0]  \n"
     ]
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "# Initialize Afinn sentiment analyzer\n",
    "afinn = Afinn()\n",
    "\n",
    "# Function to calculate sentiment score for each word\n",
    "def calculate_word_sentiment(review):\n",
    "    words = review.split()\n",
    "    scores = [afinn.score(word) for word in words]\n",
    "    return scores\n",
    "\n",
    "# Calculate sentiment scores for each word in each review\n",
    "reduced_sample['word_sentiment_scores'] = reduced_sample['review_text'].apply(calculate_word_sentiment)\n",
    "\n",
    "# Print the result\n",
    "print(reduced_sample.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8176860148032723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Prepare your data\n",
    "# Use the word sentiment scores as features\n",
    "# Convert list of word sentiment scores to fixed size arrays or take mean/sum\n",
    "X = reduced_sample['word_sentiment_scores'].apply(lambda x: sum(x) / len(x) if len(x) > 0 else 0).values.reshape(-1, 1)\n",
    "y = reduced_sample['review_score']\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Train the model\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1: My name is Commander Shepard and this game that ruined my grades\n",
      "Review Score: 1\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review 2: EPIC and LEGENDARY game\n",
      "Review Score: 1\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review 3: ♥♥♥♥♥♥♥♥\n",
      "Review Score: 1\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review 4: I played this game for a few years and it made me puke constantly and have bloody diarrhea every day. 10/10 A++++++ would play again\n",
      "Review Score: 1\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Accuracy: 0.8177\n",
      "Precision: 0.8245\n",
      "Recall: 0.9874\n",
      "F1 Score: 0.8986\n",
      "ROC-AUC: 0.5203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Select random samples with at least one having a review score less than 0\n",
    "n_samples = 5\n",
    "sample_indices = np.random.choice(X_test.shape[0], n_samples - 1, replace=False)\n",
    "negative_sample_index = df[df['review_score'] < 0].sample(1, random_state=1).index\n",
    "\n",
    "# Extract reviews, scores, and predictions\n",
    "sample_reviews = df.loc[negative_sample_index.union(sample_indices), 'review_text']\n",
    "sample_scores = df.loc[negative_sample_index.union(sample_indices), 'review_score']\n",
    "sample_preds = clf.predict(X_test[sample_indices])\n",
    "\n",
    "# Print the reviews, review scores, and corresponding predicted sentiments\n",
    "for idx, (review, score, pred) in enumerate(zip(sample_reviews, sample_scores, sample_preds)):\n",
    "    print(f\"Review {idx + 1}: {review}\\nReview Score: {score}\\nPredicted Sentiment: {'Positive' if pred == 1 else 'Negative'}\\n\")\n",
    "\n",
    "# Calculate additional performance metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'ROC-AUC: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.data.path.append('C:/Users/josh/nltk_data')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
