{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Application: Sentimental Analysis on Steam Reviews (Possibly?)\n",
    "\n",
    "## Team\n",
    "\n",
    "* Gabriel Aracena\n",
    "* Joshua Canode\n",
    "* Aaron Galicia\n",
    "\n",
    "### Project Description\n",
    "\n",
    "A key area of knowledge in data analytics is the ability to extract meaning from text. This assignment provides the foundational skills in this area by detecting whether a text conveys a positive or negative message.\n",
    "\n",
    "Analyze the sentiment (e.g., negative, neutral, positive) conveyed in a large body (corpus) of texts using the NLTK package in Python. Complete the steps below. Then, write a comprehensive technical report as a Python Jupyter notebook to include all code, code comments, all outputs, plots, and analysis. Make sure the project documentation contains a) Problem statement, b) Algorithm of the solution, c) Analysis of the findings, and d) References.\n",
    "\n",
    "## Abstract\n",
    "\n",
    "TODO\n",
    "\n",
    "### Data Preparation:\n",
    "\n",
    "TODO\n",
    "\n",
    "### ANN Model Building:\n",
    "\n",
    "TODO\n",
    "\n",
    "\n",
    "### Training the ANN:\n",
    "\n",
    "\n",
    "\n",
    "### Evaluation:\n",
    "\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "\n",
    "## Interpretation and Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app_id        app_name                                        review_text  \\\n",
      "0      10  Counter-Strike                                    Ruined my life.   \n",
      "1      10  Counter-Strike  This will be more of a ''my experience with th...   \n",
      "2      10  Counter-Strike                      This game saved my virginity.   \n",
      "3      10  Counter-Strike  • Do you like original games? • Do you like ga...   \n",
      "4      10  Counter-Strike           Easy to learn, hard to master.             \n",
      "\n",
      "   review_score  review_votes  \n",
      "0             1             0  \n",
      "1             1             1  \n",
      "2             1             0  \n",
      "3             1             0  \n",
      "4             1             1  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327   Best bowling simulator 2014 10/10 It has good ...             1   \n",
      "1662500  Marvel characters? Check. Tons of loot? Check....             1   \n",
      "2061157  This game while its not the original is defina...             1   \n",
      "1171799  This game ♥♥♥♥ing awesome ,You can be professi...             1   \n",
      "1450080  If you are high, play this game. 420/420 would...             1   \n",
      "\n",
      "         review_votes  \n",
      "301327              1  \n",
      "1662500             0  \n",
      "2061157             0  \n",
      "1171799             0  \n",
      "1450080             0  \n",
      "(64171, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sampling the dataset to decrease run time\n",
    "sample_size = int(0.01 * len(df))\n",
    "reduced_sample = df.sample(n=sample_size, random_state=42) \n",
    "print(reduced_sample.head())\n",
    "\n",
    "print(reduced_sample.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "# Specify the NLTK data path explicitly\n",
    "nltk.data.path.append('C:/Users/josh/nltk_data')  # Replace with the actual path to your nltk_data directory\n",
    "\n",
    "# Download the required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_lower(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return text\n",
    "\n",
    "# tokenize the text\n",
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "        cleaned_text = \" \".join(tokens)\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    if isinstance(text, str):\n",
    "        # Removing Punctuation\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in string.punctuation]\n",
    "        cleaned_text = \" \".join(tokens)\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Stop Word Removal\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        cleaned_text = \" \".join(filtered_tokens)\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "import re\n",
    "# handleing things like 10/10\n",
    "def replace_good_ratings(text):\n",
    "    pattern = r'(\\d+)/(\\d+)'\n",
    "\n",
    "    def replace(match):\n",
    "        numerator = int(match.group(1))\n",
    "        denominator = int(match.group(2))\n",
    "\n",
    "        # Check if the numerator is not 0\n",
    "        if numerator != 0:\n",
    "            return 'great'\n",
    "        else:\n",
    "            return 'very bad'  # Replace \"0/number\" with \"very bad\"\n",
    "\n",
    "    cleaned_text = re.sub(pattern, replace, text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case the text\n",
    "reduced_sample['review_text'] = df['review_text'].apply(preprocess_text_lower)\n",
    "# 6 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(tokenize_text)\n",
    "# 24 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(remove_punctuation)\n",
    "# 31 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(remove_stopwords)\n",
    "# 50 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace good ratings\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(replace_good_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327    best bowling simulator 2014 great good storyline             1   \n",
      "1662500  marvel characters check tons loot check tons c...             1   \n",
      "2061157  game original definately one best renditions p...             1   \n",
      "1171799  game ♥♥♥♥ing awesome professional heister fun ...             1   \n",
      "1450080                    high play game great would dank             1   \n",
      "\n",
      "         review_votes  \n",
      "301327              1  \n",
      "1662500             0  \n",
      "2061157             0  \n",
      "1171799             0  \n",
      "1450080             0  \n"
     ]
    }
   ],
   "source": [
    "# Print the result (original and cleaned text for the first few rows)\n",
    "print(reduced_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64171, 5)\n",
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327    best bowling simulator 2014 great good storyline             1   \n",
      "1662500  marvel characters check tons loot check tons c...             1   \n",
      "2061157  game original definately one best renditions p...             1   \n",
      "1171799  game ♥♥♥♥ing awesome professional heister fun ...             1   \n",
      "1450080                    high play game great would dank             1   \n",
      "\n",
      "         review_votes  sentiment_scores  \n",
      "301327              1          0.000461  \n",
      "1662500             0          0.000660  \n",
      "2061157             0          0.000735  \n",
      "1171799             0          0.000597  \n",
      "1450080             0          0.000420  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "print(reduced_sample.shape)\n",
    "\n",
    "# 1. TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust the number of features as needed\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(reduced_sample['review_text'])\n",
    "tfidf_matrix = csr_matrix(tfidf_matrix)\n",
    "\n",
    "# 2. Calculate Sentiment Scores in Batches and Append to DataFrame\n",
    "batch_size = 1000  # Number of rows to process in each batch\n",
    "sentiment_scores = []\n",
    "\n",
    "for start in range(0, len(reduced_sample), batch_size):\n",
    "    end = min(start + batch_size, len(reduced_sample))\n",
    "    batch_tfidf_matrix = tfidf_matrix[start:end]\n",
    "    batch_scores = batch_tfidf_matrix.mean(axis=1)\n",
    "    sentiment_scores.extend(batch_scores)\n",
    "\n",
    "# Add the 'sentiment_scores' column to 'reduced_sample' from the TF-IDF scores\n",
    "reduced_sample['sentiment_scores'] = sentiment_scores\n",
    "\n",
    "\n",
    "# slopy very bad code... \n",
    "def extract_sentiment_score(scores):\n",
    "    try:\n",
    "        return float(scores[0][0][0][0])\n",
    "    except (IndexError, ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "reduced_sample['sentiment_scores'] = reduced_sample['sentiment_scores'].apply(extract_sentiment_score)\n",
    "\n",
    "\n",
    "# Print the result\n",
    "print(reduced_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327    best bowling simulator 2014 great good storyline             1   \n",
      "1662500  marvel characters check tons loot check tons c...             1   \n",
      "2061157  game original definately one best renditions p...             1   \n",
      "1171799  game ♥♥♥♥ing awesome professional heister fun ...             1   \n",
      "1450080                    high play game great would dank             1   \n",
      "\n",
      "         review_votes  sentiment_scores  vader_sentiment_score  \\\n",
      "301327              1          0.000461                 0.9042   \n",
      "1662500             0          0.000660                 0.9674   \n",
      "2061157             0          0.000735                 0.8516   \n",
      "1171799             0          0.000597                 0.9460   \n",
      "1450080             0          0.000420                 0.7579   \n",
      "\n",
      "                                     word_sentiment_scores  \n",
      "301327                 [3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0]  \n",
      "1662500  [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2061157  [0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1171799  [0.0, 0.0, 4.0, 0.0, 0.0, 4.0, 0.0, 1.0, 4.0, ...  \n",
      "1450080                     [0.0, 0.0, 0.0, 3.0, 0.0, 0.0]  \n"
     ]
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "# Initialize Afinn sentiment analyzer\n",
    "afinn = Afinn()\n",
    "\n",
    "# Function to calculate sentiment score for each word\n",
    "def calculate_word_sentiment(review):\n",
    "    words = review.split()\n",
    "    scores = [afinn.score(word) for word in words]\n",
    "    return scores\n",
    "\n",
    "# Calculate sentiment scores for each word in each review\n",
    "reduced_sample['word_sentiment_scores'] = reduced_sample['review_text'].apply(calculate_word_sentiment)\n",
    "\n",
    "# Print the result\n",
    "print(reduced_sample.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8176860148032723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Prepare your data\n",
    "# Use the word sentiment scores as features\n",
    "# Convert list of word sentiment scores to fixed size arrays or take mean/sum\n",
    "X = reduced_sample['word_sentiment_scores'].apply(lambda x: sum(x) / len(x) if len(x) > 0 else 0).values.reshape(-1, 1)\n",
    "y = reduced_sample['review_score']\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Train the model\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1: ♥♥♥♥\n",
      "Review Score: 1\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review 2: start the game ----------- get into a server---------------first round------all the server starts to say fire in the hole fire in the hole firf rifrifrfirfirifri ------------ the awp scope is made in paint app --------guns are useless sub guns are useless too --------- the game is AWP and m4 and ak-47----- any thing els suck  but still love it 10/10\n",
      "Review Score: 1\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review 3: ] hideradar  ] hud_draw 0 ] net_graph 0   console commands for intense inreal life warfare experience  bind 'a' '+left; rate 9000; cl_cmdrate 30; cl_updaterate 30'  bind 'w' '+forward; rate 2500; cl_cmdrate 30; cl_updaterate 30'  bind 'd' '+right; rate 7500; cl_cmdrate 30; cl_updaterate 30'  bind 'mouse1' 'attack1; rate 25000; cl_cmdrate 101; cl_cmdrate 101'\n",
      "Review Score: 1\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review 4: Very nice game\n",
      "Review Score: 1\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Accuracy: 0.8177\n",
      "Precision: 0.8245\n",
      "Recall: 0.9874\n",
      "F1 Score: 0.8986\n",
      "ROC-AUC: 0.5203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Select random samples with at least one having a review score less than 0\n",
    "n_samples = 5\n",
    "sample_indices = np.random.choice(X_test.shape[0], n_samples - 1, replace=False)\n",
    "negative_sample_index = df[df['review_score'] < 0].sample(1, random_state=1).index\n",
    "\n",
    "# Extract reviews, scores, and predictions\n",
    "sample_reviews = df.loc[negative_sample_index.union(sample_indices), 'review_text']\n",
    "sample_scores = df.loc[negative_sample_index.union(sample_indices), 'review_score']\n",
    "sample_preds = clf.predict(X_test[sample_indices])\n",
    "\n",
    "# Print the reviews, review scores, and corresponding predicted sentiments\n",
    "for idx, (review, score, pred) in enumerate(zip(sample_reviews, sample_scores, sample_preds)):\n",
    "    print(f\"Review {idx + 1}: {review}\\nReview Score: {score}\\nPredicted Sentiment: {'Positive' if pred == 1 else 'Negative'}\\n\")\n",
    "\n",
    "# Calculate additional performance metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'ROC-AUC: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This game is amazing!\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: Worst game ever.\n",
      "Sentiment: Negative\n",
      "\n",
      "Review: I love this game, it's the best!\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: I hate this game, it's terrible.\n",
      "Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_review_sentiment(review_text, clf, vectorizer):\n",
    "    # Preprocess the review text (you should use the same preprocessing steps you used on the training data)\n",
    "    # ...\n",
    "\n",
    "    # Calculate sentiment scores\n",
    "    sentiment_scores = [afinn.score(word) for word in review_text.split()]\n",
    "    mean_sentiment_score = sum(sentiment_scores) / len(sentiment_scores) if len(sentiment_scores) > 0 else 0\n",
    "\n",
    "    # Transform the review text using the TF-IDF vectorizer\n",
    "    tfidf_vector = vectorizer.transform([review_text])\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = clf.predict([[mean_sentiment_score]])\n",
    "    return 'Positive' if prediction[0] == 1 else 'Negative'\n",
    "\n",
    "# Test the model on sample review texts\n",
    "sample_reviews = [\n",
    "    \"This game is amazing!\",\n",
    "    \"Worst game ever.\",\n",
    "    \"I love this game, it's the best!\",\n",
    "    \"I hate this game, it's terrible.\",\n",
    "]\n",
    "for review in sample_reviews:\n",
    "    sentiment = predict_review_sentiment(review, clf, tfidf_vectorizer)\n",
    "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.data.path.append('C:/Users/josh/nltk_data')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
