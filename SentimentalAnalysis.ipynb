{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Application: Sentimental Analysis on Steam Reviews (Possibly?)\n",
    "\n",
    "## Team\n",
    "\n",
    "* Gabriel Aracena\n",
    "* Joshua Canode\n",
    "* Aaron Galicia\n",
    "\n",
    "### Project Description\n",
    "\n",
    "A key area of knowledge in data analytics is the ability to extract meaning from text. This assignment provides the foundational skills in this area by detecting whether a text conveys a positive or negative message.\n",
    "\n",
    "Analyze the sentiment (e.g., negative, neutral, positive) conveyed in a large body (corpus) of texts using the NLTK package in Python. Complete the steps below. Then, write a comprehensive technical report as a Python Jupyter notebook to include all code, code comments, all outputs, plots, and analysis. Make sure the project documentation contains a) Problem statement, b) Algorithm of the solution, c) Analysis of the findings, and d) References.\n",
    "\n",
    "## Abstract\n",
    "\n",
    "TODO\n",
    "\n",
    "### Data Preparation:\n",
    "\n",
    "TODO\n",
    "\n",
    "### ANN Model Building:\n",
    "\n",
    "TODO\n",
    "\n",
    "\n",
    "### Training the ANN:\n",
    "\n",
    "\n",
    "\n",
    "### Evaluation:\n",
    "\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "\n",
    "## Interpretation and Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app_id        app_name                                        review_text  \\\n",
      "0      10  Counter-Strike                                    Ruined my life.   \n",
      "1      10  Counter-Strike  This will be more of a ''my experience with th...   \n",
      "2      10  Counter-Strike                      This game saved my virginity.   \n",
      "3      10  Counter-Strike  • Do you like original games? • Do you like ga...   \n",
      "4      10  Counter-Strike           Easy to learn, hard to master.             \n",
      "\n",
      "   review_score  review_votes  \n",
      "0             1             0  \n",
      "1             1             1  \n",
      "2             1             0  \n",
      "3             1             0  \n",
      "4             1             1  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327   Best bowling simulator 2014 10/10 It has good ...             1   \n",
      "1662500  Marvel characters? Check. Tons of loot? Check....             1   \n",
      "2061157  This game while its not the original is defina...             1   \n",
      "1171799  This game ♥♥♥♥ing awesome ,You can be professi...             1   \n",
      "1450080  If you are high, play this game. 420/420 would...             1   \n",
      "\n",
      "         review_votes  \n",
      "301327              1  \n",
      "1662500             0  \n",
      "2061157             0  \n",
      "1171799             0  \n",
      "1450080             0  \n",
      "(64171, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sampling the dataset to decrease run time\n",
    "sample_size = int(0.01 * len(df))\n",
    "reduced_sample = df.sample(n=sample_size, random_state=42) \n",
    "print(reduced_sample.head())\n",
    "\n",
    "print(reduced_sample.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "# Specify the NLTK data path explicitly\n",
    "nltk.data.path.append('C:/Users/josh/nltk_data')  # Replace with the actual path to your nltk_data directory\n",
    "\n",
    "# Download the required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_lower(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return text\n",
    "\n",
    "# tokenize the text\n",
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "        cleaned_text = \" \".join(tokens)\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    if isinstance(text, str):\n",
    "        # Removing Punctuation\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in string.punctuation]\n",
    "        cleaned_text = \" \".join(tokens)\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Stop Word Removal\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        cleaned_text = \" \".join(filtered_tokens)\n",
    "    else:\n",
    "        cleaned_text = \"\"\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "import re\n",
    "# handleing things like 10/10\n",
    "def replace_good_ratings(text):\n",
    "    pattern = r'(\\d+)/(\\d+)'\n",
    "\n",
    "    def replace(match):\n",
    "        numerator = int(match.group(1))\n",
    "        denominator = int(match.group(2))\n",
    "\n",
    "        # Check if the numerator is not 0\n",
    "        if numerator != 0:\n",
    "            return 'great'\n",
    "        else:\n",
    "            return 'very bad'  # Replace \"0/number\" with \"very bad\"\n",
    "\n",
    "    cleaned_text = re.sub(pattern, replace, text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case the text\n",
    "reduced_sample['review_text'] = df['review_text'].apply(preprocess_text_lower)\n",
    "# 6 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(tokenize_text)\n",
    "# 24 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(remove_punctuation)\n",
    "# 31 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(remove_stopwords)\n",
    "# 50 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace good ratings\n",
    "reduced_sample['review_text'] = reduced_sample['review_text'].apply(replace_good_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327    best bowling simulator 2014 great good storyline             1   \n",
      "1662500  marvel characters check tons loot check tons c...             1   \n",
      "2061157  game original definately one best renditions p...             1   \n",
      "1171799  game ♥♥♥♥ing awesome professional heister fun ...             1   \n",
      "1450080                    high play game great would dank             1   \n",
      "\n",
      "         review_votes  \n",
      "301327              1  \n",
      "1662500             0  \n",
      "2061157             0  \n",
      "1171799             0  \n",
      "1450080             0  \n"
     ]
    }
   ],
   "source": [
    "# Print the result (original and cleaned text for the first few rows)\n",
    "print(reduced_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64171, 5)\n",
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327    best bowling simulator 2014 great good storyline             1   \n",
      "1662500  marvel characters check tons loot check tons c...             1   \n",
      "2061157  game original definately one best renditions p...             1   \n",
      "1171799  game ♥♥♥♥ing awesome professional heister fun ...             1   \n",
      "1450080                    high play game great would dank             1   \n",
      "\n",
      "         review_votes  sentiment_scores  \n",
      "301327              1          0.000461  \n",
      "1662500             0          0.000660  \n",
      "2061157             0          0.000735  \n",
      "1171799             0          0.000597  \n",
      "1450080             0          0.000420  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "print(reduced_sample.shape)\n",
    "\n",
    "# 1. TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust the number of features as needed\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(reduced_sample['review_text'])\n",
    "tfidf_matrix = csr_matrix(tfidf_matrix)\n",
    "\n",
    "# 2. Calculate Sentiment Scores in Batches and Append to DataFrame\n",
    "batch_size = 1000  # Number of rows to process in each batch\n",
    "sentiment_scores = []\n",
    "\n",
    "for start in range(0, len(reduced_sample), batch_size):\n",
    "    end = min(start + batch_size, len(reduced_sample))\n",
    "    batch_tfidf_matrix = tfidf_matrix[start:end]\n",
    "    batch_scores = batch_tfidf_matrix.mean(axis=1)\n",
    "    sentiment_scores.extend(batch_scores)\n",
    "\n",
    "# Add the 'sentiment_scores' column to 'reduced_sample' from the TF-IDF scores\n",
    "reduced_sample['sentiment_scores'] = sentiment_scores\n",
    "\n",
    "\n",
    "# slopy very bad code... \n",
    "def extract_sentiment_score(scores):\n",
    "    try:\n",
    "        return float(scores[0][0][0][0])\n",
    "    except (IndexError, ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "reduced_sample['sentiment_scores'] = reduced_sample['sentiment_scores'].apply(extract_sentiment_score)\n",
    "\n",
    "\n",
    "# Print the result\n",
    "print(reduced_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         app_id                                   app_name  \\\n",
      "301327    12210  Grand Theft Auto IV: The Complete Edition   \n",
      "1662500  226320                        Marvel Heroes Omega   \n",
      "2061157  236450           PAC-MAN Championship Edition DX+   \n",
      "1171799  218620                                   PAYDAY 2   \n",
      "1450080  221640                              Super Hexagon   \n",
      "\n",
      "                                               review_text  review_score  \\\n",
      "301327    best bowling simulator 2014 great good storyline             1   \n",
      "1662500  marvel characters check tons loot check tons c...             1   \n",
      "2061157  game original definately one best renditions p...             1   \n",
      "1171799  game ♥♥♥♥ing awesome professional heister fun ...             1   \n",
      "1450080                    high play game great would dank             1   \n",
      "\n",
      "         review_votes  sentiment_scores  \\\n",
      "301327              1          0.000461   \n",
      "1662500             0          0.000660   \n",
      "2061157             0          0.000735   \n",
      "1171799             0          0.000597   \n",
      "1450080             0          0.000420   \n",
      "\n",
      "                                     word_sentiment_scores  \n",
      "301327                 [3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0]  \n",
      "1662500  [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2061157  [0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1171799  [0.0, 0.0, 4.0, 0.0, 0.0, 4.0, 0.0, 1.0, 4.0, ...  \n",
      "1450080                     [0.0, 0.0, 0.0, 3.0, 0.0, 0.0]  \n"
     ]
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "# Initialize Afinn sentiment analyzer\n",
    "afinn = Afinn()\n",
    "\n",
    "# Function to calculate sentiment score for each word\n",
    "def calculate_word_sentiment(review):\n",
    "    words = review.split()\n",
    "    scores = [afinn.score(word) for word in words]\n",
    "    return scores\n",
    "\n",
    "# Calculate sentiment scores for each word in each review\n",
    "reduced_sample['word_sentiment_scores'] = reduced_sample['review_text'].apply(calculate_word_sentiment)\n",
    "\n",
    "# Print the result\n",
    "print(reduced_sample.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8668484612388001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Combine review_text and sentiment scores\n",
    "combined_features = reduced_sample['review_text'].astype(str) + ' ' + reduced_sample['word_sentiment_scores'].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "# TF-IDF vectorization for text\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "text_features = tfidf_vectorizer.fit_transform(combined_features)\n",
    "\n",
    "# Convert sentiment scores to a numpy array\n",
    "sentiment_scores = reduced_sample['word_sentiment_scores'].apply(lambda x: sum(x) / len(x) if len(x) > 0 else 0).values.reshape(-1, 1)\n",
    "\n",
    "# Concatenate text and sentiment features\n",
    "X = hstack((text_features, sentiment_scores))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Text: best bowling simulator 2014 great good storyline\n",
      "Actual Review Score: 1\n",
      "Predicted Review Score: 1\n",
      "\n",
      "\n",
      "Review Text: marvel characters check tons loot check tons characters/classes check interesting events check lfg gtfo solo marvel fan diablo fan good marvel fan still better d3 2013\n",
      "Actual Review Score: -1\n",
      "Predicted Review Score: 1\n",
      "\n",
      "\n",
      "Review Text: game original definately one best renditions pac-man ever totally recommend even though really came 2007 2013 steam -_-\n",
      "Actual Review Score: 1\n",
      "Predicted Review Score: 1\n",
      "\n",
      "\n",
      "Review Text: game ♥♥♥♥ing awesome professional heister fun play friend fun add workshop mod\n",
      "Actual Review Score: -1\n",
      "Predicted Review Score: 1\n",
      "\n",
      "\n",
      "Review Text: high play game great would dank\n",
      "Actual Review Score: 1\n",
      "Predicted Review Score: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through a few examples from the test set\n",
    "num_examples_to_print = 5  # Change this to the number of examples you want to print\n",
    "\n",
    "for i in range(num_examples_to_print):\n",
    "    review_text = reduced_sample['review_text'].iloc[i]  # Get the review text\n",
    "    review_score = y_test.iloc[i]  # Get the corresponding review score from the test set\n",
    "    predicted_score = y_pred[i]  # Get the predicted review score\n",
    "    \n",
    "    print(f\"Review Text: {review_text}\")\n",
    "    print(f\"Actual Review Score: {review_score}\")\n",
    "    print(f\"Predicted Review Score: {predicted_score}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This game is amazing!\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: Worst game ever.\n",
      "Sentiment: Negative\n",
      "\n",
      "Review: I love this game, it's the best!\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: I hate this game, it's terrible.\n",
      "Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define the function to predict sentiment\n",
    "def predict_review_sentiment(review_text, clf, vectorizer, afinn):\n",
    "    # Preprocess the review text (you should use the same preprocessing steps you used on the training data)\n",
    "    # ...\n",
    "\n",
    "    # Calculate sentiment scores\n",
    "    sentiment_scores = [afinn.score(word) for word in review_text.split()]\n",
    "    mean_sentiment_score = sum(sentiment_scores) / len(sentiment_scores) if len(sentiment_scores) > 0 else 0\n",
    "\n",
    "    # Transform the review text using the TF-IDF vectorizer\n",
    "    text_features = vectorizer.transform([review_text])\n",
    "    \n",
    "    # Combine text and sentiment features\n",
    "    combined_features = hstack((text_features, mean_sentiment_score))\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = clf.predict(combined_features)\n",
    "    return 'Positive' if prediction[0] == 1 else 'Negative'\n",
    "\n",
    "# Test the model on sample review texts\n",
    "sample_reviews = [\n",
    "    \"This game is amazing!\",\n",
    "    \"Worst game ever.\",\n",
    "    \"I love this game, it's the best!\",\n",
    "    \"I hate this game, it's terrible.\",\n",
    "]\n",
    "\n",
    "# Loop through sample reviews\n",
    "for review in sample_reviews:\n",
    "    sentiment = predict_review_sentiment(review, clf, tfidf_vectorizer, afinn)\n",
    "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This game is amazing!\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: Worst game ever.\n",
      "Sentiment: Negative\n",
      "\n",
      "Review: I love this game, it's the best!\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: I hate this game, it's terrible.\n",
      "Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_review_sentiment(review_text, clf, vectorizer):\n",
    "    # Preprocess the review text (you should use the same preprocessing steps you used on the training data)\n",
    "    # ...\n",
    "\n",
    "    # Calculate sentiment scores\n",
    "    sentiment_scores = [afinn.score(word) for word in review_text.split()]\n",
    "    mean_sentiment_score = sum(sentiment_scores) / len(sentiment_scores) if len(sentiment_scores) > 0 else 0\n",
    "\n",
    "    # Transform the review text using the TF-IDF vectorizer\n",
    "    tfidf_vector = vectorizer.transform([review_text])\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = clf.predict([[mean_sentiment_score]])\n",
    "    return 'Positive' if prediction[0] == 1 else 'Negative'\n",
    "\n",
    "# Test the model on sample review texts\n",
    "sample_reviews = [\n",
    "    \"This game is amazing!\",\n",
    "    \"Worst game ever.\",\n",
    "    \"I love this game, it's the best!\",\n",
    "    \"I hate this game, it's terrible.\",\n",
    "]\n",
    "for review in sample_reviews:\n",
    "    sentiment = predict_review_sentiment(review, clf, tfidf_vectorizer)\n",
    "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.data.path.append('C:/Users/josh/nltk_data')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
