{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network: NBA Player Dataset Team Optimazitation\n",
    "\n",
    "## Team\n",
    "\n",
    "Gabriel Aracena\n",
    "Joshua Canode\n",
    "Aaron Galicia\n",
    "\n",
    "### Project Description\n",
    "\n",
    "Select a pool of 100 players from the data set, within a 5-year window.\n",
    "Define \"optimal team\" based on your decision of the player characteristics necessary to build a team. For example, if all 5 players are 3-point shooters, the team will miss defenders, which will make it unbalanced.\n",
    "Your task is to identify the optimal team of 5 players from that pool.\n",
    "Examine the multilayer neural network MLP architecture depicted in the \"CST-435 An Artificial Neural Network Model Image.\"\n",
    "Build a deep artificial neural network MLP to include the following: a) 1 input layer, b) as many hidden layers as you deem necessary, and c) an output layer fully connected to the hidden layers.\n",
    "Explain your architecture and how the basketball player characteristics are used as inputs.\n",
    "Activate the MLP by performing the following steps:\n",
    "\n",
    "Starting at the input layer, forward propagate the patterns of the training data through the network to generate an output.\n",
    "Based on the network's output, calculate the error that we want to minimize using a cost function that we will describe later.\n",
    "Backpropagate the error, find its derivative with respect to each weight in the network, and update the model.\n",
    "Repeat steps 1 through 3 for multiple epochs and learn the weights of the MLP.\n",
    "Use forward propagation to calculate the network output and apply a threshold function to obtain the predicted class labels in the one-hot representation.\n",
    "Interpret the output of your MLP in the context of selecting an optimal basketball team.\n",
    "\n",
    "## Abstract\n",
    "\n",
    "The objective is to use a deep artificial neural network (ANN) to determine an optimal team composition from a pool of basketball players. Given player characteristics, we want to identify the best five players that result in a balanced team.\n",
    "\n",
    "### Data Preparation:\n",
    "\n",
    "* Load the NBA Players Dataset.\n",
    "* Filter to get a pool of 100 players from a random 5-year window.\n",
    "* Normalize/Standardize player characteristics.\n",
    "\n",
    "### ANN Model Building:\n",
    "\n",
    "* Design a Multi-layer Perceptron (MLP) based on the architecture of the CST-435 An Artificial Neural Network Model Image (see below)\n",
    "* Define layers: Input layer, Hidden layers, and Output layer.\n",
    "* Determine the appropriate activation function, optimizer, and loss function for the MLP.\n",
    "\n",
    "![ANNModel](ANNModel.png)\n",
    "\n",
    "### Training the ANN:\n",
    "\n",
    "* Forward propagation: Use player characteristics to propagate input data through the network and generate an output.\n",
    "* Calculate the error using a predefined cost function.\n",
    "* Backpropagate the error to update model weights.\n",
    "* Repeat the above steps for several epochs.\n",
    "\n",
    "### Evaluation and Team Selection:\n",
    "\n",
    "* Use forward propagation on the trained ANN to predict player effectiveness or class labels.\n",
    "* Apply a threshold function to these predictions.\n",
    "* Select the top five players that meet the optimal team criteria.\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "* Input Layer: This layer will have neurons equal to the number of player characteristics we're considering (e.g. points, assists, offensive rebounds, defensive rebounds,etc.).\n",
    "* Hidden Layers: Multiple hidden layers can be used to capture intricate patterns and relationships. We initially thought we would do 5 hidden layers, one for each position,  but we decided to stick with only a single layer for simplicity and might change that later. \n",
    "* Output Layer: This layer can have neurons equal to the number of classes or roles in the team we're predicting for (e.g., point guard, shooting guard, center, etc.). Each neuron will give the likelihood of a player fitting that role.\n",
    "\n",
    "## Activation and Threshold Function\n",
    "\n",
    "During forward propagation, each neuron processes input data and transmits it to the next layer. An activation function is applied to this data. For this model, we can use the ReLU (Rectified Linear Unit) activation function for hidden layers due to its computational efficiency and the ability to handle non-linearities. The softmax function might be applied to the output layer as it provides a probability distribution.\n",
    "\n",
    "After obtaining the output, a threshold function is applied to convert continuous values into distinct class labels. In this case, it can be the player's most likely role in the team.\n",
    "\n",
    "## Interpretation and Conclusion\n",
    "\n",
    "The final output provides us with a categorization of each player in our pool. By examining the predicted class labels and the associated probabilities, we can:\n",
    "* Identify which role or position each player is most suited for.\n",
    "* Select the top players for each role to form our optimal team.\n",
    "\n",
    "We are going to define target values for each position and use hope to use that in the end of each training to classify if the output team was good or not. \n",
    "\n",
    "It's worth noting that the \"optimal\" team is contingent on the data provided and the neural network's training. For better results, the model should be regularly trained with updated data, and other external factors (like team chemistry and current form) should also be considered in real-world scenarios. For our optimal team we defined some weights based on each player position that will take into account the 2 most important stats for each position according to our criteria. See Definig player types bellow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defining Player types    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n5 center\\n\\theight = 0.5\\n\\tweight = 0.5\\n\\n4 forward\\n\\tnet_rating = 0.6\\n\\treb = 0.4\\n\\n3 small forward\\n\\tast_pct = 0.3\\n\\tusg_pct = 0.7\\n\\n2 guard\\n\\tpts = 0.8\\n\\tts_pct = 0.2\\n\\n1 point guard\\n\\tast = 0.8\\n\\tgp = 0.2\\n\\n\\n'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "5 center\n",
    "\theight = 0.5\n",
    "\tweight = 0.5\n",
    "\n",
    "4 forward\n",
    "\tnet_rating = 0.6\n",
    "\treb = 0.4\n",
    "\n",
    "3 small forward\n",
    "\tast_pct = 0.3\n",
    "\tusg_pct = 0.7\n",
    "\n",
    "2 guard\n",
    "\tpts = 0.8\n",
    "\tts_pct = 0.2\n",
    "\n",
    "1 point guard\n",
    "\tast = 0.8\n",
    "\tgp = 0.2\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the DataFrame:\n",
      "   Unnamed: 0        player_name team_abbreviation   age  player_height  \\\n",
      "0           0      Dennis Rodman               CHI  36.0         198.12   \n",
      "1           1  Dwayne Schintzius               LAC  28.0         215.90   \n",
      "2           2       Earl Cureton               TOR  39.0         205.74   \n",
      "3           3        Ed O'Bannon               DAL  24.0         203.20   \n",
      "4           4        Ed Pinckney               MIA  34.0         205.74   \n",
      "\n",
      "   player_weight                      college country draft_year draft_round  \\\n",
      "0      99.790240  Southeastern Oklahoma State     USA       1986           2   \n",
      "1     117.933920                      Florida     USA       1990           1   \n",
      "2      95.254320                Detroit Mercy     USA       1979           3   \n",
      "3     100.697424                         UCLA     USA       1995           1   \n",
      "4     108.862080                    Villanova     USA       1985           1   \n",
      "\n",
      "   ...  pts   reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
      "0  ...  5.7  16.1  3.1        16.1     0.186     0.323    0.100   0.479   \n",
      "1  ...  2.3   1.5  0.3        12.3     0.078     0.151    0.175   0.430   \n",
      "2  ...  0.8   1.0  0.4        -2.1     0.105     0.102    0.103   0.376   \n",
      "3  ...  3.7   2.3  0.6        -8.7     0.060     0.149    0.167   0.399   \n",
      "4  ...  2.4   2.4  0.2       -11.2     0.109     0.179    0.127   0.611   \n",
      "\n",
      "   ast_pct   season  \n",
      "0    0.113  1996-97  \n",
      "1    0.048  1996-97  \n",
      "2    0.148  1996-97  \n",
      "3    0.077  1996-97  \n",
      "4    0.040  1996-97  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Tail of the DataFrame:\n",
      "       Unnamed: 0      player_name team_abbreviation   age  player_height  \\\n",
      "12300       12300  Markieff Morris               MIA  32.0         205.74   \n",
      "12301       12301   Markelle Fultz               ORL  24.0         193.04   \n",
      "12302       12302     Marcus Smart               BOS  28.0         193.04   \n",
      "12303       12303   Marcus Garrett               MIA  23.0         195.58   \n",
      "12304       12304     Micah Potter               DET  24.0         208.28   \n",
      "\n",
      "       player_weight         college country draft_year draft_round  ...  \\\n",
      "12300     111.130040          Kansas     USA       2011           1  ...   \n",
      "12301      94.800728      Washington     USA       2017           1  ...   \n",
      "12302      99.790240  Oklahoma State     USA       2014           1  ...   \n",
      "12303      92.986360          Kansas     USA  Undrafted   Undrafted  ...   \n",
      "12304     112.490816       Wisconsin     USA  Undrafted   Undrafted  ...   \n",
      "\n",
      "        pts  reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
      "12300   7.6  2.6  1.4         4.5     0.059     0.089    0.197   0.547   \n",
      "12301  10.8  2.7  5.5        -5.3     0.010     0.116    0.265   0.517   \n",
      "12302  12.1  3.8  5.9         9.3     0.018     0.093    0.179   0.540   \n",
      "12303   1.1  1.9  0.6         5.8     0.072     0.108    0.086   0.280   \n",
      "12304   4.0  3.0  0.0       -56.4     0.095     0.125    0.148   0.505   \n",
      "\n",
      "       ast_pct   season  \n",
      "12300    0.116  2021-22  \n",
      "12301    0.448  2021-22  \n",
      "12302    0.245  2021-22  \n",
      "12303    0.069  2021-22  \n",
      "12304    0.000  2021-22  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the file path\n",
    "file_path = \"all_seasons.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the head (first few rows) of the DataFrame\n",
    "print(\"Head of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the tail (last few rows) of the DataFrame\n",
    "print(\"\\nTail of the DataFrame:\")\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0263600000000002\n",
      "1.02918\n",
      "1.001\n",
      "1.1804000000000001\n",
      "1.204001248\n"
     ]
    }
   ],
   "source": [
    "# Defining target stats based on player types\n",
    "\n",
    "PROPORTINALITY_FACTOR = 1000\n",
    "\n",
    "def calculateTargetValue(position, stat1, stat2):\n",
    "    # Point Guard: ast = 0.8 gp = 0.2\n",
    "    # Shooting Guard: pts = 0.8 ts_pct = 0.2\n",
    "    if (position == 1 or position == 2):\n",
    "        weightedValue = ((stat1 + PROPORTINALITY_FACTOR) * 0.8 + (stat2 + PROPORTINALITY_FACTOR) * 0.2 ) / PROPORTINALITY_FACTOR\n",
    "        return weightedValue\n",
    "    \n",
    "    # Small Forward: ast_pct = 0.3 usg_pct = 0.7\n",
    "    elif (position == 3):\n",
    "        weightedValue = ((stat1 + PROPORTINALITY_FACTOR) * 0.3 + (stat2 + PROPORTINALITY_FACTOR) * 0.7 ) / PROPORTINALITY_FACTOR\n",
    "        return weightedValue\n",
    "    # Forward: net_rating = 0.6 reb = 0.4\n",
    "    elif (position == 4):\n",
    "        weightedValue = ((stat1 + PROPORTINALITY_FACTOR) * 0.6 + (stat2 + PROPORTINALITY_FACTOR) * 0.4 ) / PROPORTINALITY_FACTOR\n",
    "        return weightedValue\n",
    "    # Center: height = 0.5 weight = 0.5\n",
    "    elif (position == 5):\n",
    "        weightedValue = ((stat1 + PROPORTINALITY_FACTOR) * 0.6 + (stat2 + PROPORTINALITY_FACTOR) * 0.4 ) / PROPORTINALITY_FACTOR\n",
    "        return weightedValue\n",
    "\n",
    "MAXIMUM_ASSIST = max(df['ast'])\n",
    "MAXIMUM_GP = max(df['gp'])\n",
    "MAXIMUM_PTS = max(df['pts'])\n",
    "MAXIMUM_SHOOTING_RATE = max(df['ts_pct'])\n",
    "MAXIMUM_ASSIST_PCTG = max(df['ast_pct'])\n",
    "MAXIMUM_USG_PCT = max(df['usg_pct']) \n",
    "MAXIMUM_NET_RATING = max(df['net_rating'])\n",
    "MAXIMUM_REB = max(df['oreb_pct'])\n",
    "MAXIMUM_HEIGHT = max(df['player_height']) \n",
    "MAXIMUM_WEIGHT = max(df['player_weight']) \n",
    "\n",
    "# The target stats will be 80% of the maximum value (it will be really hard to get 100% all the time since we are going to only use 100 players out of the whole dataset)\n",
    "TARGET_POINT_GUARD_VALUE = calculateTargetValue(1, MAXIMUM_ASSIST, MAXIMUM_GP)\n",
    "TARGET_SHOOTING_GUARD_VALUE = calculateTargetValue(2, MAXIMUM_PTS, MAXIMUM_SHOOTING_RATE)\n",
    "TARGET_SMALL_FORWARD_VALUE = calculateTargetValue(3, MAXIMUM_ASSIST_PCTG, MAXIMUM_USG_PCT)\n",
    "TARGET_FORWARD_VALUE = calculateTargetValue(4, MAXIMUM_NET_RATING, MAXIMUM_REB)\n",
    "TARGET_CENTER_VALUE = calculateTargetValue(5, MAXIMUM_HEIGHT, MAXIMUM_WEIGHT)\n",
    "\n",
    "print(TARGET_POINT_GUARD_VALUE)\n",
    "print(TARGET_SHOOTING_GUARD_VALUE)\n",
    "print(TARGET_SMALL_FORWARD_VALUE)\n",
    "print(TARGET_FORWARD_VALUE)\n",
    "print(TARGET_CENTER_VALUE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0        player_name team_abbreviation   age  player_height  \\\n",
      "0            0      Dennis Rodman               CHI  36.0         198.12   \n",
      "1            1  Dwayne Schintzius               LAC  28.0         215.90   \n",
      "2            2       Earl Cureton               TOR  39.0         205.74   \n",
      "3            3        Ed O'Bannon               DAL  24.0         203.20   \n",
      "4            4        Ed Pinckney               MIA  34.0         205.74   \n",
      "..         ...                ...               ...   ...            ...   \n",
      "95          95     Glenn Robinson               MIL  24.0         200.66   \n",
      "96          96         Grant Long               DET  31.0         205.74   \n",
      "97          97      Greg Anderson               SAS  33.0         208.28   \n",
      "98          98       Greg Anthony               VAN  29.0         185.42   \n",
      "99          99      Greg Dreiling               DAL  33.0         215.90   \n",
      "\n",
      "    player_weight                      college country  draft_year  \\\n",
      "0       99.790240  Southeastern Oklahoma State     USA        1996   \n",
      "1      117.933920                      Florida     USA        1996   \n",
      "2       95.254320                Detroit Mercy     USA        1996   \n",
      "3      100.697424                         UCLA     USA        1996   \n",
      "4      108.862080                    Villanova     USA        1996   \n",
      "..            ...                          ...     ...         ...   \n",
      "95     106.594120                       Purdue     USA        1996   \n",
      "96     112.490816             Eastern Michigan     USA        1996   \n",
      "97     113.398000                      Houston     USA        1996   \n",
      "98      81.646560             Nevada-Las Vegas     USA        1996   \n",
      "99     120.201880                       Kansas     USA        1996   \n",
      "\n",
      "   draft_round  ...   pts   reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  \\\n",
      "0            2  ...   5.7  16.1  3.1        16.1     0.186     0.323    0.100   \n",
      "1            1  ...   2.3   1.5  0.3        12.3     0.078     0.151    0.175   \n",
      "2            3  ...   0.8   1.0  0.4        -2.1     0.105     0.102    0.103   \n",
      "3            1  ...   3.7   2.3  0.6        -8.7     0.060     0.149    0.167   \n",
      "4            1  ...   2.4   2.4  0.2       -11.2     0.109     0.179    0.127   \n",
      "..         ...  ...   ...   ...  ...         ...       ...       ...      ...   \n",
      "95           1  ...  21.1   6.3  3.1        -2.9     0.051     0.144    0.278   \n",
      "96           2  ...   5.0   3.4  0.6         4.0     0.096     0.150    0.154   \n",
      "97           1  ...   3.9   5.5  0.4       -14.2     0.109     0.219    0.106   \n",
      "98           1  ...   9.5   2.8  6.3        -9.4     0.015     0.099    0.177   \n",
      "99           2  ...   2.0   1.9  0.3        -8.0     0.059     0.192    0.114   \n",
      "\n",
      "    ts_pct  ast_pct   season  \n",
      "0    0.479    0.113  1996-97  \n",
      "1    0.430    0.048  1996-97  \n",
      "2    0.376    0.148  1996-97  \n",
      "3    0.399    0.077  1996-97  \n",
      "4    0.611    0.040  1996-97  \n",
      "..     ...      ...      ...  \n",
      "95   0.528    0.146  1996-97  \n",
      "96   0.523    0.058  1996-97  \n",
      "97   0.531    0.033  1996-97  \n",
      "98   0.526    0.358  1996-97  \n",
      "99   0.466    0.048  1996-97  \n",
      "\n",
      "[100 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "df['draft_year'] = df['season'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# Define the target year and the window size\n",
    "enough_players = False\n",
    "window_size = 5\n",
    "while not enough_players:\n",
    "    target_year = 2000 # random.randint(min(df['draft_year']), max(df['draft_year']))\n",
    "    start_year = target_year - window_size\n",
    "    end_year = target_year\n",
    "    filtered_df = df[(df['draft_year'] >= start_year) & (df['draft_year'] <= end_year)]\n",
    "    \n",
    "    if len(filtered_df) >= 100:\n",
    "        enough_players = True\n",
    "        selected_df = filtered_df.head(100)\n",
    "        '''random.seed(42)\n",
    "        selected_players = random.sample(range(len(filtered_df)), 100)\n",
    "        selected_df = filtered_df.iloc[selected_players]\n",
    "        '''\n",
    "        print(selected_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 2ms/step - loss: 138.9114\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 138.0354\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 137.2332\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 136.5267\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 135.8200\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 135.2169\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 134.6548\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 134.1706\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 133.7338\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 133.3277\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 132.9689\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 132.6519\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 132.3578\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 132.1112\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 131.8673\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 131.6649\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 131.4726\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 131.3023\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 131.1524\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 131.0180\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.9001\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.7931\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.6980\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.6175\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.5415\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.4711\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.4047\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.3458\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.2901\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.2384\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.1896\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.1451\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.1037\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.0668\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.0341\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.0034\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 129.9762\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 129.9489\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 129.9229\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.8989\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.8750\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.8549\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.8350\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.8166\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.7994\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.7827\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.7680\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.7546\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.7418\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.7299\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 43.7275\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 43.2544\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 42.8404\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 42.4537\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 42.0859\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 41.7780\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 41.4983\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 41.2567\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 41.0390\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 40.8605\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 40.6947\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 40.5555\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 40.4406\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 40.3335\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 40.2368\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 40.1484\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 40.0711\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 40.0020\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.9404\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.8861\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.8395\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.7969\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.7568\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.7219\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.6873\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.6576\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.6299\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.6053\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.5816\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.5609\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.5408\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.5216\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.5039\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.4879\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.4728\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.4582\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.4458\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.4344\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.4233\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.4136\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.4036\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.3950\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.3863\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.3784\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 39.3706\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.3638\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.3574\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.3513\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.3457\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 39.3406\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 0.1305\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1072\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0876\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0706\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0564\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0447\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0357\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0287\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0234\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0194\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0119\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0104\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0092\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0076\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0070\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0064\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0060\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0053\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0050\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0046\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0044\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0042\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0041\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0033\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0023\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 101.6441\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 101.2379\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 100.9019\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 100.5451\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 100.2759\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 99.9696\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 99.7421\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 99.5556\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 99.3977\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 99.2644\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 99.1487\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 99.0329\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.9351\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.8563\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.7785\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.7092\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.6479\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.5972\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.5502\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.5064\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.4627\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.4229\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.3847\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.3538\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.3231\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.2947\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.2665\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.2432\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.2191\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.1942\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.1736\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.1517\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.1325\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.1133\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.0946\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.0757\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.0607\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.0461\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.0330\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.0182\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 98.0043\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 97.9901\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 97.9764\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 97.9636\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 97.9506\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 97.9371\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 97.9245\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 97.9103\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 97.9007\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 97.8887\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\aaron\\Documents\\Code\\CST435\\NBA.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/aaron/Documents/Code/CST435/NBA.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39melif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/aaron/Documents/Code/CST435/NBA.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     target \u001b[39m=\u001b[39m (selected_df[\u001b[39m'\u001b[39m\u001b[39mplayer_height\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m+\u001b[39m selected_df[\u001b[39m'\u001b[39m\u001b[39mplayer_weight\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m) \u001b[39m/\u001b[39m TARGET_CENTER_VALUE\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/aaron/Documents/Code/CST435/NBA.ipynb#X11sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m models[i]\u001b[39m.\u001b[39;49mfit(selected_features, target, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:873\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 873\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m    874\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    875\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    876\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    877\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 694\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn    \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    695\u001b[0m     \u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(\n\u001b[0;32m    696\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[0;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:176\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 176\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    169\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:398\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[0;32m    396\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[1;32m--> 398\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[0;32m    399\u001b[0m     args, kwargs, func_graph)\n\u001b[0;32m    401\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:305\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[0;32m    304\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 305\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    306\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m    307\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m    308\u001b[0m         args,\n\u001b[0;32m    309\u001b[0m         kwargs,\n\u001b[0;32m    310\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    311\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    312\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m    313\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[0;32m    314\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m    316\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m    317\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    322\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1055\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1052\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m   1054\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1055\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[0;32m   1057\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:597\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    594\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    595\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 597\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    598\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m   \u001b[39mreturn\u001b[39;00m api\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m     42\u001b[0m       original_func,\n\u001b[0;32m     43\u001b[0m       args,\n\u001b[0;32m     44\u001b[0m       kwargs,\n\u001b[0;32m     45\u001b[0m       options\u001b[39m=\u001b[39;49mconverter\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m     46\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     47\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m     48\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     49\u001b[0m       ))\n\u001b[0;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileyb_rlvxq.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1322\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1318\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1319\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m     )\n\u001b[0;32m   1321\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1322\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1323\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1324\u001b[0m     outputs,\n\u001b[0;32m   1325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1326\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1327\u001b[0m )\n\u001b[0;32m   1328\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1669\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1671\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1672\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1673\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3250\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3248\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   3249\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 3250\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4048\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   4046\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   4047\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 4048\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1303\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1303\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1304\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1305\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1081\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m   1080\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 1081\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m   1082\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m   1083\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1139\u001b[0m, in \u001b[0;36mModel.compute_loss\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the total loss, validate it, and return it.\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \n\u001b[0;32m   1090\u001b[0m \u001b[39mSubclasses can optionally override this method to provide custom loss\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[39m  is the case when called by `Model.test_step`).\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[39mdel\u001b[39;00m x  \u001b[39m# The default implementation does not use `x`.\u001b[39;00m\n\u001b[1;32m-> 1139\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompiled_loss(\n\u001b[0;32m   1140\u001b[0m     y, y_pred, sample_weight, regularization_losses\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlosses\n\u001b[0;32m   1141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py:317\u001b[0m, in \u001b[0;36mLossesContainer.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[0;32m    313\u001b[0m total_loss_mean_values \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mcast_losses_to_common_dtype(\n\u001b[0;32m    314\u001b[0m     total_loss_mean_values\n\u001b[0;32m    315\u001b[0m )\n\u001b[0;32m    316\u001b[0m total_total_loss_mean_value \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39madd_n(total_loss_mean_values)\n\u001b[1;32m--> 317\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_total_loss_mean\u001b[39m.\u001b[39;49mupdate_state(\n\u001b[0;32m    318\u001b[0m     total_total_loss_mean_value, sample_weight\u001b[39m=\u001b[39;49mbatch_dim\n\u001b[0;32m    319\u001b[0m )\n\u001b[0;32m    321\u001b[0m loss_values \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mcast_losses_to_common_dtype(loss_values)\n\u001b[0;32m    322\u001b[0m total_loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39madd_n(loss_values)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\metrics_utils.py:77\u001b[0m, in \u001b[0;36mupdate_state_wrapper.<locals>.decorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTrying to run metric.update_state in replica context when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe metric was not created in TPUStrategy scope. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMake sure the keras Metric is created in TPUstrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mscope. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     76\u001b[0m \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mgraph_context_for_symbolic_tensors(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 77\u001b[0m     update_op \u001b[39m=\u001b[39m update_state_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[39mif\u001b[39;00m update_op \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# update_op will be None in eager execution.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     metric_obj\u001b[39m.\u001b[39madd_update(update_op)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py:140\u001b[0m, in \u001b[0;36mMetric.__new__.<locals>.update_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m control_status \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    137\u001b[0m ag_update_state \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    138\u001b[0m     obj_update_state, control_status\n\u001b[0;32m    139\u001b[0m )\n\u001b[1;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m ag_update_state(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py:526\u001b[0m, in \u001b[0;36mReduce.update_state\u001b[1;34m(self, values, sample_weight)\u001b[0m\n\u001b[0;32m    521\u001b[0m             values \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(\n\u001b[0;32m    522\u001b[0m                 values, axis\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(weight_ndim, ndim))\n\u001b[0;32m    523\u001b[0m             )\n\u001b[0;32m    524\u001b[0m     values \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmultiply(values, sample_weight)\n\u001b[1;32m--> 526\u001b[0m value_sum \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mreduce_sum(values)\n\u001b[0;32m    527\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies([value_sum]):\n\u001b[0;32m    528\u001b[0m     update_total_op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal\u001b[39m.\u001b[39massign_add(value_sum)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:2392\u001b[0m, in \u001b[0;36mreduce_sum\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2329\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.reduce_sum\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreduce_sum\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   2330\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   2331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_sum\u001b[39m(input_tensor, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2332\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Computes the sum of elements across dimensions of a tensor.\u001b[39;00m\n\u001b[0;32m   2333\u001b[0m \n\u001b[0;32m   2334\u001b[0m \u001b[39m  This is the reduction operation for the elementwise `tf.math.add` op.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2389\u001b[0m \u001b[39m  @end_compatibility\u001b[39;00m\n\u001b[0;32m   2390\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2392\u001b[0m   \u001b[39mreturn\u001b[39;00m reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[0;32m   2393\u001b[0m                               _ReductionDims(input_tensor, axis))\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:2404\u001b[0m, in \u001b[0;36mreduce_sum_with_dims\u001b[1;34m(input_tensor, axis, keepdims, name, dims)\u001b[0m\n\u001b[0;32m   2396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_sum_with_dims\u001b[39m(input_tensor,\n\u001b[0;32m   2397\u001b[0m                          axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2398\u001b[0m                          keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   2399\u001b[0m                          name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2400\u001b[0m                          dims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2401\u001b[0m   keepdims \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mbool\u001b[39m(keepdims)\n\u001b[0;32m   2402\u001b[0m   \u001b[39mreturn\u001b[39;00m _may_reduce_to_scalar(\n\u001b[0;32m   2403\u001b[0m       keepdims, axis,\n\u001b[1;32m-> 2404\u001b[0m       gen_math_ops\u001b[39m.\u001b[39;49m_sum(input_tensor, dims, keepdims, name\u001b[39m=\u001b[39;49mname))\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:13010\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[0;32m  13008\u001b[0m   keep_dims \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m  13009\u001b[0m keep_dims \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_bool(keep_dims, \u001b[39m\"\u001b[39m\u001b[39mkeep_dims\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m> 13010\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m  13011\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mSum\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, reduction_indices\u001b[39m=\u001b[39;49maxis, keep_dims\u001b[39m=\u001b[39;49mkeep_dims,\n\u001b[0;32m  13012\u001b[0m              name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m  13013\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m  13014\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:795\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    790\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    791\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    792\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    793\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    794\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    796\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    797\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    799\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    803\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3381\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3378\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3379\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3380\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3381\u001b[0m   ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39;49mfrom_node_def(\n\u001b[0;32m   3382\u001b[0m       node_def,\n\u001b[0;32m   3383\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3384\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3385\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3386\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3387\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3388\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3389\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[0;32m   3390\u001b[0m   )\n\u001b[0;32m   3391\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3392\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1889\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1886\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   1888\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 1889\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   1890\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Operation(c_op, GraphTensor)\n\u001b[0;32m   1891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(g)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1748\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1744\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   1745\u001b[0m                                          serialized)\n\u001b[0;32m   1747\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1748\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   1749\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1750\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CELL HERE\n",
    "# Defining the model\n",
    "\n",
    "#input_shape = (100, 10)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape = (10,)),  # 8 input features\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')   # Output layer with 5 nodes (one for each player type)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the neural network model for position prediction\n",
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(10,)),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')  # Predict a score between 0 and 1\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Create a model for each position\n",
    "models = {i: create_model() for i in range(1, 6)}\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "selected_features = scaler.fit_transform(selected_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']])\n",
    "\n",
    "# Train a model for each position using the ideal values as targets\n",
    "for i in range(1, 6):\n",
    "    if i == 1:\n",
    "        target = (selected_df['ast']*0.8 + selected_df['gp']*0.2) / TARGET_POINT_GUARD_VALUE\n",
    "    elif i == 2:\n",
    "        target = (selected_df['pts']*0.8 + selected_df['ts_pct']*0.2) / TARGET_SHOOTING_GUARD_VALUE\n",
    "    elif i == 3:\n",
    "        target = (selected_df['ast_pct']*0.3 + selected_df['usg_pct']*0.7) / TARGET_SMALL_FORWARD_VALUE\n",
    "    elif i == 4:\n",
    "        target = (selected_df['net_rating']*0.6 + selected_df['oreb_pct']*0.4) / TARGET_FORWARD_VALUE\n",
    "    elif i == 5:\n",
    "        target = (selected_df['player_height']*0.5 + selected_df['player_weight']*0.5) / TARGET_CENTER_VALUE\n",
    "    models[i].fit(selected_features, target, epochs=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Optimal Team:\n",
      "Position 1: Gary Payton\n",
      "Position 2: Gheorghe Muresan\n",
      "Position 3: Derrick McKey\n",
      "Position 4: Derrick McKey\n",
      "Position 5: Eric Murdock\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each player for each position and select the optimal player\n",
    "optimal_team = {}\n",
    "for i in range(1, 6):\n",
    "    scores = models[i].predict(selected_features).flatten()\n",
    "    best_player_idx = scores.argmax()\n",
    "    optimal_team[i] = selected_df.iloc[best_player_idx].name\n",
    "    # Remove this player so they aren't selected again\n",
    "    selected_features = np.delete(selected_features, best_player_idx, axis=0)\n",
    "\n",
    "print(\"Optimal Team:\")\n",
    "for pos, player_idx in optimal_team.items():\n",
    "    player_name = df.loc[df.index == player_idx, 'player_name'].values[0]\n",
    "    print(f\"Position {pos}: {player_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining positions for dataset\n",
    "# Create new column called position for selected_df\n",
    "# Do a for loop 5 times where we use the function calculateTargetValue(i, stat1, stat2) and check the biggest return value for\n",
    "# every value of i to then populate the new column position with the value of i that had the biggest value for that specific player \n",
    "def determine_position(row):\n",
    "    best_value = float('-inf')\n",
    "    best_position = None\n",
    "\n",
    "    for i in range(1, 6):  # Loop 5 times as you mentioned\n",
    "        if i == 1:\n",
    "            value = calculateTargetValue(i, row['ast'], row['gp']) - TARGET_POINT_GUARD_VALUE\n",
    "        elif i == 2:\n",
    "            value = calculateTargetValue(i, row['pts'], row['ts_pct']) - TARGET_SHOOTING_GUARD_VALUE\n",
    "        elif i == 3:\n",
    "            value = calculateTargetValue(i, row['ast_pct'], row['usg_pct']) - TARGET_SMALL_FORWARD_VALUE\n",
    "        elif i == 4:\n",
    "            value = calculateTargetValue(i, row['net_rating'], row['oreb_pct']) - TARGET_FORWARD_VALUE\n",
    "        elif i == 5:\n",
    "            value = calculateTargetValue(i, row['player_height'], row['player_weight']) - TARGET_CENTER_VALUE\n",
    "\n",
    "        if value > best_value:\n",
    "            best_value = value\n",
    "            best_position = i\n",
    "    return best_position\n",
    "\n",
    "selected_df = selected_df.copy()\n",
    "selected_df['position'] = selected_df.apply(determine_position, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 121ms/step - loss: 1.6641 - accuracy: 0.1250 - val_loss: 1.5189 - val_accuracy: 0.1500\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5307 - accuracy: 0.1875 - val_loss: 1.3906 - val_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4081 - accuracy: 0.3000 - val_loss: 1.2701 - val_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.2873 - accuracy: 0.4375 - val_loss: 1.1558 - val_accuracy: 0.6000\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1773 - accuracy: 0.5875 - val_loss: 1.0487 - val_accuracy: 0.8500\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0725 - accuracy: 0.7875 - val_loss: 0.9485 - val_accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9750 - accuracy: 0.9000 - val_loss: 0.8559 - val_accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8841 - accuracy: 0.9625 - val_loss: 0.7710 - val_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8023 - accuracy: 0.9875 - val_loss: 0.6933 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7264 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6234 - accuracy: 1.0000\n",
      "Validation Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df, val_df = train_test_split(selected_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract the features and labels for training and validation datasets\n",
    "X_train = train_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']].values\n",
    "y_train = train_df[['position']].values.ravel()\n",
    "\n",
    "X_val = val_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']].values\n",
    "y_val = val_df[['position']].values.ravel()\n",
    "\n",
    "# Apply normalization\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n",
      "    Player Index  True Position  Predicted Position\n",
      "0             83              3                   4\n",
      "1             53              3                   4\n",
      "2             70              3                   4\n",
      "3             45              3                   4\n",
      "4             44              3                   4\n",
      "5             39              3                   4\n",
      "6             22              3                   4\n",
      "7             80              3                   4\n",
      "8             10              3                   4\n",
      "9              0              3                   4\n",
      "10            18              3                   4\n",
      "11            30              3                   4\n",
      "12            73              3                   4\n",
      "13            33              3                   4\n",
      "14            90              3                   4\n",
      "15             4              3                   4\n",
      "16            76              3                   4\n",
      "17            77              3                   4\n",
      "18            12              3                   4\n",
      "19            31              3                   4\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "predictions = model.predict(X_val)\n",
    "predicted_positions = [tf.argmax(pred).numpy() + 1 for pred in predictions]\n",
    "\n",
    "# Create a DataFrame for results\n",
    "results_df = pd.DataFrame({\n",
    "    'Player Index': val_df.index,\n",
    "    'True Position': y_val,\n",
    "    'Predicted Position': predicted_positions\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Optimal Team:\n",
      "Position 1: Player Index 88\n",
      "Position 2: Player Index 73\n",
      "Position 3: Player Index 21\n",
      "Position 4: Player Index 75\n",
      "Position 5: Player Index 72\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each player for each position and select the optimal player\n",
    "optimal_team = {}\n",
    "for i in range(1, 6):\n",
    "    scores = models[i].predict(selected_features).flatten()\n",
    "    best_player_idx = scores.argmax()\n",
    "    optimal_team[i] = selected_df.iloc[best_player_idx].name\n",
    "    # Remove this player so they aren't selected again\n",
    "    selected_features = np.delete(selected_features, best_player_idx, axis=0)\n",
    "\n",
    "print(\"Optimal Team:\")\n",
    "for pos, player_idx in optimal_team.items():\n",
    "    print(f\"Position {pos}: Player Index {player_idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
