{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network: NBA Player Dataset Team Optimazitation\n",
    "\n",
    "## Team\n",
    "\n",
    "Gabriel Aracena\n",
    "Joshua Canode\n",
    "Aaron Galicia\n",
    "\n",
    "### Project Description\n",
    "\n",
    "Select a pool of 100 players from the data set, within a 5-year window.\n",
    "Define \"optimal team\" based on your decision of the player characteristics necessary to build a team. For example, if all 5 players are 3-point shooters, the team will miss defenders, which will make it unbalanced.\n",
    "Your task is to identify the optimal team of 5 players from that pool.\n",
    "Examine the multilayer neural network MLP architecture depicted in the \"CST-435 An Artificial Neural Network Model Image.\"\n",
    "Build a deep artificial neural network MLP to include the following: a) 1 input layer, b) as many hidden layers as you deem necessary, and c) an output layer fully connected to the hidden layers.\n",
    "Explain your architecture and how the basketball player characteristics are used as inputs.\n",
    "Activate the MLP by performing the following steps:\n",
    "\n",
    "Starting at the input layer, forward propagate the patterns of the training data through the network to generate an output.\n",
    "Based on the network's output, calculate the error that we want to minimize using a cost function that we will describe later.\n",
    "Backpropagate the error, find its derivative with respect to each weight in the network, and update the model.\n",
    "Repeat steps 1 through 3 for multiple epochs and learn the weights of the MLP.\n",
    "Use forward propagation to calculate the network output and apply a threshold function to obtain the predicted class labels in the one-hot representation.\n",
    "Interpret the output of your MLP in the context of selecting an optimal basketball team.\n",
    "\n",
    "## Abstract\n",
    "\n",
    "The objective is to use a deep artificial neural network (ANN) to determine an optimal team composition from a pool of basketball players. Given player characteristics, we want to identify the best five players that result in a balanced team.\n",
    "\n",
    "### Data Preparation:\n",
    "\n",
    "* Load the NBA Players Dataset.\n",
    "* Filter to get a pool of 100 players from a random 5-year window.\n",
    "* Normalize/Standardize player characteristics.\n",
    "\n",
    "### ANN Model Building:\n",
    "\n",
    "* Design a Multi-layer Perceptron (MLP) based on the architecture of the CST-435 An Artificial Neural Network Model Image (see below)\n",
    "* Define layers: Input layer, Hidden layers, and Output layer.\n",
    "* Determine the appropriate activation function, optimizer, and loss function for the MLP.\n",
    "\n",
    "![ANNModel](ANNModel.png)\n",
    "\n",
    "### Training the ANN:\n",
    "\n",
    "* Forward propagation: Use player characteristics to propagate input data through the network and generate an output.\n",
    "* Calculate the error using a predefined cost function.\n",
    "* Backpropagate the error to update model weights.\n",
    "* Repeat the above steps for several epochs.\n",
    "\n",
    "### Evaluation and Team Selection:\n",
    "\n",
    "* Use forward propagation on the trained ANN to predict player effectiveness or class labels.\n",
    "* Apply a threshold function to these predictions.\n",
    "* Select the top five players that meet the optimal team criteria.\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "* Input Layer: This layer will have neurons equal to the number of player characteristics we're considering (e.g. points, assists, offensive rebounds, defensive rebounds,etc.).\n",
    "* Hidden Layers: Multiple hidden layers can be used to capture intricate patterns and relationships. We initially thought we would do 5 hidden layers, one for each position,  but we decided to stick with only a single layer for simplicity and might change that later. \n",
    "* Output Layer: This layer can have neurons equal to the number of classes or roles in the team we're predicting for (e.g., point guard, shooting guard, center, etc.). Each neuron will give the likelihood of a player fitting that role.\n",
    "\n",
    "## Activation and Threshold Function\n",
    "\n",
    "During forward propagation, each neuron processes input data and transmits it to the next layer. An activation function is applied to this data. For this model, we can use the ReLU (Rectified Linear Unit) activation function for hidden layers due to its computational efficiency and the ability to handle non-linearities. The softmax function might be applied to the output layer as it provides a probability distribution.\n",
    "\n",
    "After obtaining the output, a threshold function is applied to convert continuous values into distinct class labels. In this case, it can be the player's most likely role in the team.\n",
    "\n",
    "## Interpretation and Conclusion\n",
    "\n",
    "The final output provides us with a categorization of each player in our pool. By examining the predicted class labels and the associated probabilities, we can:\n",
    "* Identify which role or position each player is most suited for.\n",
    "* Select the top players for each role to form our optimal team.\n",
    "\n",
    "We are going to define target values for each position and use hope to use that in the end of each training to classify if the output team was good or not. \n",
    "\n",
    "It's worth noting that the \"optimal\" team is contingent on the data provided and the neural network's training. For better results, the model should be regularly trained with updated data, and other external factors (like team chemistry and current form) should also be considered in real-world scenarios. For our optimal team we defined some weights based on each player position that will take into account the 2 most important stats for each position according to our criteria. See Definig player types bellow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defining Player types    \n",
    "\n",
    "After research, the teams will be made up of different positions: center, foward, small forward, guard, and point guard. These positions requre different specialties. Making use of the statistics provided by the CSV, we have chosen two weights that control what factors are important to the role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n5 center\\n\\theight = 0.5\\n\\tweight = 0.5\\n\\n4 forward\\n\\tnet_rating = 0.6\\n\\treb = 0.4\\n\\n3 small forward\\n\\tast_pct = 0.3\\n\\tusg_pct = 0.7\\n\\n2 guard\\n\\tpts = 0.8\\n\\tts_pct = 0.2\\n\\n1 point guard\\n\\tast = 0.8\\n\\tgp = 0.2\\n\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "5 center\n",
    "\theight = 0.5\n",
    "\tweight = 0.5\n",
    "\n",
    "4 forward\n",
    "\tnet_rating = 0.6\n",
    "\treb = 0.4\n",
    "\n",
    "3 small forward\n",
    "\tast_pct = 0.3\n",
    "\tusg_pct = 0.7\n",
    "\n",
    "2 guard\n",
    "\tpts = 0.8\n",
    "\tts_pct = 0.2\n",
    "\n",
    "1 point guard\n",
    "\tast = 0.8\n",
    "\tgp = 0.2\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the DataFrame:\n",
      "   Unnamed: 0        player_name team_abbreviation   age  player_height  \\\n",
      "0           0      Dennis Rodman               CHI  36.0         198.12   \n",
      "1           1  Dwayne Schintzius               LAC  28.0         215.90   \n",
      "2           2       Earl Cureton               TOR  39.0         205.74   \n",
      "3           3        Ed O'Bannon               DAL  24.0         203.20   \n",
      "4           4        Ed Pinckney               MIA  34.0         205.74   \n",
      "\n",
      "   player_weight                      college country draft_year draft_round  \\\n",
      "0      99.790240  Southeastern Oklahoma State     USA       1986           2   \n",
      "1     117.933920                      Florida     USA       1990           1   \n",
      "2      95.254320                Detroit Mercy     USA       1979           3   \n",
      "3     100.697424                         UCLA     USA       1995           1   \n",
      "4     108.862080                    Villanova     USA       1985           1   \n",
      "\n",
      "   ...  pts   reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
      "0  ...  5.7  16.1  3.1        16.1     0.186     0.323    0.100   0.479   \n",
      "1  ...  2.3   1.5  0.3        12.3     0.078     0.151    0.175   0.430   \n",
      "2  ...  0.8   1.0  0.4        -2.1     0.105     0.102    0.103   0.376   \n",
      "3  ...  3.7   2.3  0.6        -8.7     0.060     0.149    0.167   0.399   \n",
      "4  ...  2.4   2.4  0.2       -11.2     0.109     0.179    0.127   0.611   \n",
      "\n",
      "   ast_pct   season  \n",
      "0    0.113  1996-97  \n",
      "1    0.048  1996-97  \n",
      "2    0.148  1996-97  \n",
      "3    0.077  1996-97  \n",
      "4    0.040  1996-97  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Tail of the DataFrame:\n",
      "       Unnamed: 0      player_name team_abbreviation   age  player_height  \\\n",
      "12300       12300  Markieff Morris               MIA  32.0         205.74   \n",
      "12301       12301   Markelle Fultz               ORL  24.0         193.04   \n",
      "12302       12302     Marcus Smart               BOS  28.0         193.04   \n",
      "12303       12303   Marcus Garrett               MIA  23.0         195.58   \n",
      "12304       12304     Micah Potter               DET  24.0         208.28   \n",
      "\n",
      "       player_weight         college country draft_year draft_round  ...  \\\n",
      "12300     111.130040          Kansas     USA       2011           1  ...   \n",
      "12301      94.800728      Washington     USA       2017           1  ...   \n",
      "12302      99.790240  Oklahoma State     USA       2014           1  ...   \n",
      "12303      92.986360          Kansas     USA  Undrafted   Undrafted  ...   \n",
      "12304     112.490816       Wisconsin     USA  Undrafted   Undrafted  ...   \n",
      "\n",
      "        pts  reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
      "12300   7.6  2.6  1.4         4.5     0.059     0.089    0.197   0.547   \n",
      "12301  10.8  2.7  5.5        -5.3     0.010     0.116    0.265   0.517   \n",
      "12302  12.1  3.8  5.9         9.3     0.018     0.093    0.179   0.540   \n",
      "12303   1.1  1.9  0.6         5.8     0.072     0.108    0.086   0.280   \n",
      "12304   4.0  3.0  0.0       -56.4     0.095     0.125    0.148   0.505   \n",
      "\n",
      "       ast_pct   season  \n",
      "12300    0.116  2021-22  \n",
      "12301    0.448  2021-22  \n",
      "12302    0.245  2021-22  \n",
      "12303    0.069  2021-22  \n",
      "12304    0.000  2021-22  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the file path\n",
    "file_path = \"all_seasons.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the head (first few rows) of the DataFrame\n",
    "print(\"Head of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the tail (last few rows) of the DataFrame\n",
    "print(\"\\nTail of the DataFrame:\")\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining target stats based on player types\n",
    "\n",
    "The weights decided above will be used before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculateTargetValue(position, stat1, stat2):\n",
    "    # Point Guard: ast = 0.8 gp = 0.2\n",
    "    # Shooting Guard: pts = 0.8 ts_pct = 0.2\n",
    "    if (position == 1 or position == 2):\n",
    "        weightedValue = ((stat1) * 0.8 + (stat2) * 0.2 )\n",
    "        return weightedValue\n",
    "    \n",
    "    # Small Forward: ast_pct = 0.3 usg_pct = 0.7\n",
    "    elif (position == 3):\n",
    "        weightedValue = ((stat1) * 0.3 + (stat2) * 0.7 )\n",
    "        return weightedValue\n",
    "    # Forward: net_rating = 0.6 reb = 0.4\n",
    "    elif (position == 4):\n",
    "        weightedValue = ((stat1) * 0.6 + (stat2) * 0.4 )\n",
    "        return weightedValue\n",
    "    # Center: height = 0.5 weight = 0.5\n",
    "    elif (position == 5):\n",
    "        weightedValue = ((stat1) * 0.6 + (stat2) * 0.4 )\n",
    "        return weightedValue\n",
    "\n",
    "'''MAXIMUM_ASSIST = max(df['ast'])\n",
    "MAXIMUM_GP = max(df['gp'])\n",
    "MAXIMUM_PTS = max(df['pts'])\n",
    "MAXIMUM_SHOOTING_RATE = max(df['ts_pct'])\n",
    "MAXIMUM_ASSIST_PCTG = max(df['ast_pct'])\n",
    "MAXIMUM_USG_PCT = max(df['usg_pct']) \n",
    "MAXIMUM_NET_RATING = max(df['net_rating'])\n",
    "MAXIMUM_REB = max(df['oreb_pct'])\n",
    "MAXIMUM_HEIGHT = max(df['player_height']) \n",
    "MAXIMUM_WEIGHT = max(df['player_weight']) \n",
    "\n",
    "# The target stats will be 80% of the maximum value (it will be really hard to get 100% all the time since we are going to only use 100 players out of the whole dataset)\n",
    "TARGET_POINT_GUARD_VALUE = calculateTargetValue(1, MAXIMUM_ASSIST, MAXIMUM_GP)\n",
    "TARGET_SHOOTING_GUARD_VALUE = calculateTargetValue(2, MAXIMUM_PTS, MAXIMUM_SHOOTING_RATE)\n",
    "TARGET_SMALL_FORWARD_VALUE = calculateTargetValue(3, MAXIMUM_ASSIST_PCTG, MAXIMUM_USG_PCT)\n",
    "TARGET_FORWARD_VALUE = calculateTargetValue(4, MAXIMUM_NET_RATING, MAXIMUM_REB)\n",
    "TARGET_CENTER_VALUE = calculateTargetValue(5, MAXIMUM_HEIGHT, MAXIMUM_WEIGHT)\n",
    "\n",
    "print(TARGET_POINT_GUARD_VALUE)\n",
    "print(TARGET_SHOOTING_GUARD_VALUE)\n",
    "print(TARGET_SMALL_FORWARD_VALUE)\n",
    "print(TARGET_FORWARD_VALUE)\n",
    "print(TARGET_CENTER_VALUE)'''\n",
    "# Calculate the 90th percentile for each statistic\n",
    "PERCENTILE = 0.9\n",
    "p90_assist = df['ast'].quantile(PERCENTILE)\n",
    "p90_gp = df['gp'].quantile(PERCENTILE)\n",
    "p90_pts = df['pts'].quantile(PERCENTILE)\n",
    "p90_shooting_rate = df['ts_pct'].quantile(PERCENTILE)\n",
    "p90_assist_pctg = df['ast_pct'].quantile(PERCENTILE)\n",
    "p90_usg_pct = df['usg_pct'].quantile(PERCENTILE)\n",
    "p90_net_rating = df['net_rating'].quantile(PERCENTILE)\n",
    "p90_reb = df['oreb_pct'].quantile(PERCENTILE)\n",
    "p90_height = df['player_height'].quantile(PERCENTILE)\n",
    "p90_weight = df['player_weight'].quantile(PERCENTILE)\n",
    "\n",
    "# Adjust the target values to be 80% of the 90th percentile\n",
    "TARGET_POINT_GUARD_VALUE = calculateTargetValue(1, p90_assist, p90_gp)\n",
    "TARGET_SHOOTING_GUARD_VALUE = calculateTargetValue(2, p90_pts, p90_shooting_rate)\n",
    "TARGET_SMALL_FORWARD_VALUE = calculateTargetValue(3, p90_assist_pctg, p90_usg_pct)\n",
    "TARGET_FORWARD_VALUE = calculateTargetValue(4, p90_net_rating, p90_reb)\n",
    "TARGET_CENTER_VALUE = calculateTargetValue(5, p90_height, p90_weight)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0               player_name team_abbreviation   age  \\\n",
      "7882        7882           Marvin Williams               UTA  28.0   \n",
      "9812        9812              Allen Crabbe               BKN  26.0   \n",
      "9818        9818               Alec Peters               PHX  23.0   \n",
      "8658        8658  Kentavious Caldwell-Pope               DET  23.0   \n",
      "8814        8814           Sean Kilpatrick               BKN  26.0   \n",
      "...          ...                       ...               ...   ...   \n",
      "7778        7778            Anthony Morrow               NOP  28.0   \n",
      "8698        8698         LaMarcus Aldridge               SAS  30.0   \n",
      "8957        8957            Andre Iguodala               GSW  32.0   \n",
      "9058        9058               Chris Kaman               POR  34.0   \n",
      "8154        8154             Larry Drew II               PHI  25.0   \n",
      "\n",
      "      player_height  player_weight           college country  draft_year  \\\n",
      "7882         205.74     107.501304    North Carolina     USA        2013   \n",
      "9812         198.12      97.522280        California     USA        2017   \n",
      "9818         205.74     106.594120        Valparaiso     USA        2017   \n",
      "8658         195.58      92.986360           Georgia     USA        2015   \n",
      "8814         193.04      99.336648        Cincinnati     USA        2015   \n",
      "...             ...            ...               ...     ...         ...   \n",
      "7778         195.58      95.254320      Georgia Tech     USA        2013   \n",
      "8698         210.82     108.862080             Texas     USA        2015   \n",
      "8957         198.12      97.522280           Arizona     USA        2015   \n",
      "9058         213.36     120.201880  Central Michigan     USA        2015   \n",
      "8154         187.96      81.646560              UCLA     USA        2014   \n",
      "\n",
      "     draft_round  ...   pts  reb  ast  net_rating  oreb_pct  dreb_pct  \\\n",
      "7882           1  ...   9.1  5.1  1.2        -5.6     0.055     0.179   \n",
      "9812           2  ...  13.2  4.3  1.6        -1.9     0.012     0.130   \n",
      "9818           2  ...   4.1  1.9  0.6         7.3     0.032     0.120   \n",
      "8658           1  ...  14.5  3.7  1.8         2.0     0.026     0.085   \n",
      "8814   Undrafted  ...  11.1  1.8  0.9       -12.3     0.021     0.083   \n",
      "...          ...  ...   ...  ...  ...         ...       ...       ...   \n",
      "7778   Undrafted  ...   8.4  1.8  0.8        -0.4     0.023     0.092   \n",
      "8698           1  ...  18.0  8.5  1.5        12.0     0.091     0.222   \n",
      "8957           1  ...   7.0  4.0  3.4        14.4     0.034     0.127   \n",
      "9058           1  ...   2.8  1.5  0.7       -13.2     0.077     0.170   \n",
      "8154   Undrafted  ...   3.8  1.3  3.8       -18.7     0.005     0.080   \n",
      "\n",
      "      usg_pct  ts_pct  ast_pct   season  \n",
      "7882    0.170   0.540    0.075  2013-14  \n",
      "9812    0.183   0.558    0.082  2017-18  \n",
      "9818    0.151   0.523    0.073  2017-18  \n",
      "8658    0.180   0.521    0.075  2015-16  \n",
      "8814    0.230   0.576    0.078  2015-16  \n",
      "...       ...     ...      ...      ...  \n",
      "7778    0.193   0.570    0.069  2013-14  \n",
      "8698    0.260   0.565    0.081  2015-16  \n",
      "8957    0.120   0.565    0.165  2015-16  \n",
      "9058    0.213   0.496    0.186  2015-16  \n",
      "8154    0.173   0.388    0.381  2014-15  \n",
      "\n",
      "[100 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "df['draft_year'] = df['season'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# Define the target year and the window size\n",
    "enough_players = False\n",
    "window_size = 5\n",
    "while not enough_players:\n",
    "    target_year = random.randint(min(df['draft_year']), max(df['draft_year']))\n",
    "    start_year = target_year - window_size\n",
    "    end_year = target_year\n",
    "    filtered_df = df[(df['draft_year'] >= start_year) & (df['draft_year'] <= end_year)]\n",
    "    \n",
    "    if len(filtered_df) >= 100:\n",
    "        enough_players = True\n",
    "        selected_players = random.sample(range(len(filtered_df)), 100)\n",
    "        test_df = filtered_df.iloc[selected_players]\n",
    "        '''random.seed(42)\n",
    "        selected_players = random.sample(range(len(filtered_df)), 100)\n",
    "        selected_df = filtered_df.iloc[selected_players]\n",
    "        '''\n",
    "        print(test_df)\n",
    "\n",
    "# Split the rest of the data (excluding the selected 100 players) for training\n",
    "train_df = df.drop(test_df.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and Training Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0455 - accuracy: 0.0011\n",
      "Epoch 2/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 0.0011\n",
      "Epoch 3/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 0.0011\n",
      "Epoch 4/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.0011\n",
      "Epoch 5/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.9392e-04 - accuracy: 0.0011\n",
      "Epoch 6/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.3601e-04 - accuracy: 0.0011\n",
      "Epoch 7/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.6510e-04 - accuracy: 0.0011\n",
      "Epoch 8/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.8404e-04 - accuracy: 0.0011\n",
      "Epoch 9/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.3937e-04 - accuracy: 0.0011\n",
      "Epoch 10/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.9317e-04 - accuracy: 0.0011\n",
      "Epoch 1/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.0111\n",
      "Epoch 2/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.0126\n",
      "Epoch 3/10\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 0.0011 - accuracy: 0.0126\n",
      "Epoch 4/10\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 7.8171e-04 - accuracy: 0.0126\n",
      "Epoch 5/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.4199e-04 - accuracy: 0.0126\n",
      "Epoch 6/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.5607e-04 - accuracy: 0.0126\n",
      "Epoch 7/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.3078e-04 - accuracy: 0.0126\n",
      "Epoch 8/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.0277e-04 - accuracy: 0.0126\n",
      "Epoch 9/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.4470e-04 - accuracy: 0.0126\n",
      "Epoch 10/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.7834e-04 - accuracy: 0.0126\n",
      "Epoch 1/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0302 - accuracy: 0.0023\n",
      "Epoch 2/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 0.0028\n",
      "Epoch 3/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.0028\n",
      "Epoch 4/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0012 - accuracy: 0.0028\n",
      "Epoch 5/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.8293e-04 - accuracy: 0.0028\n",
      "Epoch 6/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.4413e-04 - accuracy: 0.0028\n",
      "Epoch 7/10\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 7.3168e-04 - accuracy: 0.0028\n",
      "Epoch 8/10\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 6.7572e-04 - accuracy: 0.0028\n",
      "Epoch 9/10\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 6.4288e-04 - accuracy: 0.0028\n",
      "Epoch 10/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.7696e-04 - accuracy: 0.0027\n",
      "Epoch 1/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.5206 - accuracy: 7.3740e-04\n",
      "Epoch 2/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 7.3740e-04\n",
      "Epoch 3/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0083 - accuracy: 7.3740e-04\n",
      "Epoch 4/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 7.3740e-04\n",
      "Epoch 5/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 7.3740e-04\n",
      "Epoch 6/10\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 0.0029 - accuracy: 7.3740e-04\n",
      "Epoch 7/10\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 0.0023 - accuracy: 7.3740e-04\n",
      "Epoch 8/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 7.3740e-04\n",
      "Epoch 9/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 7.3740e-04\n",
      "Epoch 10/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 7.3740e-04\n",
      "Epoch 1/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0857 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0012 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.8996e-04 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.5026e-04 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.8384e-04 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.9163e-04 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.7906e-04 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network model for position prediction\n",
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(10,)),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='linear')  # Predict a score between 0 and 1\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a model for each position\n",
    "models = {i: create_model() for i in range(1, 6)}\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "selected_features = scaler.fit_transform(train_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']])\n",
    "names_df = train_df['player_name'] # Player Names\n",
    "\n",
    "# Train a model for each position using the ideal values as targets\n",
    "for i in range(1, 6):\n",
    "    if i == 1:\n",
    "        target = (train_df['ast']*0.8 + train_df['gp']*0.2) / TARGET_POINT_GUARD_VALUE\n",
    "    elif i == 2:\n",
    "        target = (train_df['pts']*0.8 + train_df['ts_pct']*0.2) / TARGET_SHOOTING_GUARD_VALUE\n",
    "    elif i == 3:\n",
    "        target = (train_df['ast_pct']*0.3 + train_df['usg_pct']*0.7) / TARGET_SMALL_FORWARD_VALUE\n",
    "    elif i == 4:\n",
    "        target = (train_df['net_rating']*0.6 + train_df['oreb_pct']*0.4) / TARGET_FORWARD_VALUE\n",
    "    elif i == 5:\n",
    "        target = (train_df['player_height']*0.5 + train_df['player_weight']*0.5) / TARGET_CENTER_VALUE\n",
    "    models[i].fit(selected_features, target, epochs=10)\n",
    "\n",
    "# Evaluate each player in the test set (100 players) for each position and select the optimal player\n",
    "X_test = scaler.transform(test_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Optimal Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 1s 1ms/step\n",
      "382/382 [==============================] - 1s 2ms/step\n",
      "382/382 [==============================] - 1s 2ms/step\n",
      "382/382 [==============================] - 1s 1ms/step\n",
      "382/382 [==============================] - 1s 1ms/step\n",
      "Optimal Team:\n",
      "Position 1: Chris Paul\n",
      "Position 2: James Ennis III\n",
      "Position 3: Gheorghe Muresan\n",
      "Position 4: Bruce Bowen\n",
      "Position 5: Joel Freeland\n"
     ]
    }
   ],
   "source": [
    "optimal_team = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    scores = models[i].predict(selected_features).flatten()\n",
    "    best_player_idx = scores.argmax()\n",
    "    for x, y in optimal_team.items():\n",
    "        if names_df.iloc[best_player_idx] == y:\n",
    "            selected_features = np.delete(selected_features, best_player_idx, axis=0)\n",
    "            names_df.drop(best_player_idx)\n",
    "            scores = models[i].predict(selected_features).flatten()\n",
    "            best_player_idx = scores.argmax()\n",
    "            break\n",
    "    optimal_team[i] = names_df.iloc[best_player_idx]\n",
    "    # Remove this player so they aren't selected again\n",
    "    selected_features = np.delete(selected_features, best_player_idx, axis=0)\n",
    "    names_df.drop(best_player_idx)\n",
    "\n",
    "print(\"Optimal Team:\")\n",
    "for pos, player_idx in optimal_team.items():\n",
    "    print(f\"Position {pos}: {player_idx}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above represents the optimal team that the neural network decided. When running the prediction multiple times, the players predicted by the neural network does fluctuate. This could be due to multiple factors. It is likely due to the inherent randomness in some aspects of the code and the network itself. A random time range is chosen with a random 100 players so the players will change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach: 1 ANN 5 Hidden layers\n",
    "\n",
    "Since we were unsure if it is acceptable to do the project with 5 small ANN's for each position, we decided to also do 1 singular ANN with 5 hidden layer. Each Layer will train and adjust the weights for that correspondent position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "382/382 [==============================] - 2s 3ms/step - loss: 0.1176 - accuracy: 0.8102\n",
      "Epoch 2/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0149 - accuracy: 0.9029\n",
      "Epoch 3/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0084 - accuracy: 0.9181\n",
      "Epoch 4/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9263\n",
      "Epoch 5/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0070 - accuracy: 0.9340\n",
      "Epoch 6/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0021 - accuracy: 0.9544\n",
      "Epoch 7/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0121 - accuracy: 0.9277\n",
      "Epoch 8/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9348\n",
      "Epoch 9/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9512\n",
      "Epoch 10/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.9476\n",
      "Epoch 11/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9531\n",
      "Epoch 12/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9558\n",
      "Epoch 13/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0036 - accuracy: 0.9587\n",
      "Epoch 14/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9083\n",
      "Epoch 15/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9422\n",
      "Epoch 16/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9430\n",
      "Epoch 17/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9501\n",
      "Epoch 18/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0022 - accuracy: 0.9570\n",
      "Epoch 19/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9628\n",
      "Epoch 20/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9528\n",
      "Epoch 21/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0066 - accuracy: 0.9323\n",
      "Epoch 22/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9549\n",
      "Epoch 23/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9386\n",
      "Epoch 24/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 0.9596\n",
      "Epoch 25/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9549\n",
      "Epoch 26/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9579\n",
      "Epoch 27/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 0.9661\n",
      "Epoch 28/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0037 - accuracy: 0.9575\n",
      "Epoch 29/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9606\n",
      "Epoch 30/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 0.9606\n",
      "Epoch 31/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9496\n",
      "Epoch 32/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9576\n",
      "Epoch 33/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9630\n",
      "Epoch 34/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9548\n",
      "Epoch 35/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9658\n",
      "Epoch 36/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9546\n",
      "Epoch 37/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 7.8240e-04 - accuracy: 0.9669\n",
      "Epoch 38/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9696\n",
      "Epoch 39/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9553\n",
      "Epoch 40/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 0.9645\n",
      "Epoch 41/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9544\n",
      "Epoch 42/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.5230e-04 - accuracy: 0.9671\n",
      "Epoch 43/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9511\n",
      "Epoch 44/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 0.9571\n",
      "Epoch 45/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9662\n",
      "Epoch 46/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 6.7501e-04 - accuracy: 0.9751\n",
      "Epoch 47/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9637\n",
      "Epoch 48/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 8.4893e-04 - accuracy: 0.9728\n",
      "Epoch 49/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9709\n",
      "Epoch 50/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9684\n",
      "Epoch 51/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9623\n",
      "Epoch 52/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 4.3080e-04 - accuracy: 0.9746\n",
      "Epoch 53/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 6.1728e-04 - accuracy: 0.9726\n",
      "Epoch 54/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3.1868e-04 - accuracy: 0.9792\n",
      "Epoch 55/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 5.2426e-04 - accuracy: 0.9760\n",
      "Epoch 56/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.7327e-04 - accuracy: 0.9770\n",
      "Epoch 57/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9630\n",
      "Epoch 58/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 0.9629\n",
      "Epoch 59/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9644\n",
      "Epoch 60/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.7873e-04 - accuracy: 0.9742\n",
      "Epoch 61/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9729\n",
      "Epoch 62/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.7942e-04 - accuracy: 0.9794\n",
      "Epoch 63/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0079 - accuracy: 0.9621\n",
      "Epoch 64/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9662\n",
      "Epoch 65/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.4581e-04 - accuracy: 0.9790\n",
      "Epoch 66/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.8367e-04 - accuracy: 0.9778\n",
      "Epoch 67/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.4584e-04 - accuracy: 0.9784\n",
      "Epoch 68/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9709\n",
      "Epoch 69/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0022 - accuracy: 0.9766\n",
      "Epoch 70/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 0.9689\n",
      "Epoch 71/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9734\n",
      "Epoch 72/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 6.0687e-04 - accuracy: 0.9812\n",
      "Epoch 73/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.1163e-04 - accuracy: 0.9801\n",
      "Epoch 74/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9721\n",
      "Epoch 75/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 0.9747\n",
      "Epoch 76/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9649\n",
      "Epoch 77/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.9692e-04 - accuracy: 0.9797\n",
      "Epoch 78/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.0376e-04 - accuracy: 0.9744\n",
      "Epoch 79/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9676\n",
      "Epoch 80/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0077 - accuracy: 0.9669\n",
      "Epoch 81/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 0.9707\n",
      "Epoch 82/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.6968e-04 - accuracy: 0.9795\n",
      "Epoch 83/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9674\n",
      "Epoch 84/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.7580e-04 - accuracy: 0.9791\n",
      "Epoch 85/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9762\n",
      "Epoch 86/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 9.8185e-04 - accuracy: 0.9794\n",
      "Epoch 87/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 5.6826e-04 - accuracy: 0.9785\n",
      "Epoch 88/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 2.8662e-04 - accuracy: 0.9814\n",
      "Epoch 89/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9808\n",
      "Epoch 90/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9685\n",
      "Epoch 91/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9599\n",
      "Epoch 92/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9784\n",
      "Epoch 93/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9826\n",
      "Epoch 94/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9662\n",
      "Epoch 95/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9730\n",
      "Epoch 96/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9745\n",
      "Epoch 97/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9736\n",
      "Epoch 98/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.4408e-04 - accuracy: 0.9833\n",
      "Epoch 99/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.0520e-04 - accuracy: 0.9827\n",
      "Epoch 100/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9772\n",
      "4/4 [==============================] - 0s 399us/step\n",
      "Optimal Team:\n",
      "Position 1: Player Name Russell Westbrook\n",
      "Position 2: Player Name Kristaps Porzingis\n",
      "Position 3: Player Name Udonis Haslem\n",
      "Position 4: Player Name Andre Iguodala\n",
      "Position 5: Player Name Steve Blake\n"
     ]
    }
   ],
   "source": [
    "def create_model2():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(10,)),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(5, activation='linear')  # Predict 5 scores (one for each position)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=('accuracy'))\n",
    "    return model\n",
    "\n",
    "model2 = create_model2()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train2 = scaler.fit_transform(train_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']])\n",
    "X_test2 = scaler.transform(test_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']])\n",
    "\n",
    "# Create training target values for each position\n",
    "Y_train2 = np.vstack([\n",
    "    (train_df['ast']*0.8 + train_df['gp']*0.2) / TARGET_POINT_GUARD_VALUE,\n",
    "    (train_df['pts']*0.8 + train_df['ts_pct']*0.2) / TARGET_SHOOTING_GUARD_VALUE,\n",
    "    (train_df['ast_pct']*0.3 + train_df['usg_pct']*0.7) / TARGET_SMALL_FORWARD_VALUE,\n",
    "    (train_df['net_rating']*0.6 + train_df['oreb_pct']*0.4) / TARGET_FORWARD_VALUE,\n",
    "    (train_df['player_height']*0.5 + train_df['player_weight']*0.5) / TARGET_CENTER_VALUE\n",
    "]).T\n",
    "\n",
    "model2.fit(X_train2, Y_train2, epochs=100)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions2 = model2.predict(X_test2)\n",
    "\n",
    "# Select optimal team\n",
    "optimal_team2 = {}\n",
    "for i in range(5):  # For each position\n",
    "    best_player_idx2 = predictions2[:, i].argmax()\n",
    "    optimal_team2[i + 1] = test_df.iloc[best_player_idx2].name\n",
    "    # Remove this player so they aren't selected again\n",
    "    predictions2 = np.delete(predictions2, best_player_idx2, axis=0)\n",
    "\n",
    "print(\"Optimal Team:\")\n",
    "for pos, player_idx in optimal_team2.items():\n",
    "    player_name = df.loc[df.index == player_idx, 'player_name'].values[0]\n",
    "    print(f\"Position {pos}: Player Name {player_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Both methods produce different results, though both exhibit impressively low loss functions, making it challenging to definitively determine superiority. Notably, the 5 hidden layer Artificial Neural Network (ANN) achieves higher accuracy, but this observation is limited to the specific dataset and relies on subjective judgment.\n",
    "\n",
    "It's crucial to recognize that numerous avenues for potential improvement exist to enhance accuracy. These include working with a larger dataset to account for potential duplicate player entries. Additionally, exploring architectural variations within the neural network, adjusting activation and loss functions, careful data scaling, feature engineering, and strategies to prevent overfitting offer promising opportunities.\n",
    "\n",
    "Further optimization can be achieved by tweaking training epochs, selecting optimizers, fine-tuning learning rates, and defining more precise evaluation criteria. This iterative process enables ongoing model refinement.\n",
    "\n",
    "It's worth noting that the pursuit of an ideal model is limitless, with seemingly endless possibilities for improvement. However, our progress has led to the development of a model that consistently achieves an accuracy rate exceeding 90%. This marks significant progress compared to the initial model, which had an accuracy level of approximately 1%, and we are pleased with these results.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
