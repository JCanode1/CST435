{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network: NBA Player Dataset Team Optimazitation\n",
    "\n",
    "## Team\n",
    "\n",
    "Gabriel Aracena\n",
    "Joshua Canode\n",
    "Aaron Galicia\n",
    "\n",
    "## Abstract\n",
    "\n",
    "The objective is to use a deep artificial neural network (ANN) to determine an optimal team composition from a pool of basketball players. Given player characteristics, we want to identify the best five players that result in a balanced team.\n",
    "\n",
    "### Data Preparation:\n",
    "\n",
    "* Load the NBA Players Dataset.\n",
    "* Filter to get a pool of 100 players from a random 5-year window.\n",
    "* Normalize/Standardize player characteristics.\n",
    "\n",
    "### ANN Model Building:\n",
    "\n",
    "* Design a Multi-layer Perceptron (MLP) based on the architecture of the CST-435 An Artificial Neural Network Model Image (see below)\n",
    "* Define layers: Input layer, Hidden layers, and Output layer.\n",
    "* Determine the appropriate activation function, optimizer, and loss function for the MLP.\n",
    "\n",
    "![ANNModel](ANNModel.png)\n",
    "\n",
    "### Training the ANN:\n",
    "\n",
    "* Forward propagation: Use player characteristics to propagate input data through the network and generate an output.\n",
    "* Calculate the error using a predefined cost function.\n",
    "* Backpropagate the error to update model weights.\n",
    "* Repeat the above steps for several epochs.\n",
    "\n",
    "### Evaluation and Team Selection:\n",
    "\n",
    "* Use forward propagation on the trained ANN to predict player effectiveness or class labels.\n",
    "* Apply a threshold function to these predictions.\n",
    "* Select the top five players that meet the optimal team criteria.\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "* Input Layer: This layer will have neurons equal to the number of player characteristics we're considering (e.g. points, assists, offensive rebounds, defensive rebounds,etc.).\n",
    "* Hidden Layers: Multiple hidden layers can be used to capture intricate patterns and relationships. We are going to have 5 hidden layers, each one of them will test the match for the players \n",
    "* Output Layer: This layer can have neurons equal to the number of classes or roles in the team we're predicting for (e.g., point guard, shooting guard, center, etc.). Each neuron will give the likelihood of a player fitting that role.\n",
    "\n",
    "## Activation and Threshold Function\n",
    "\n",
    "During forward propagation, each neuron processes input data and transmits it to the next layer. An activation function is applied to this data. For this model, we can use the ReLU (Rectified Linear Unit) activation function for hidden layers due to its computational efficiency and the ability to handle non-linearities. The softmax function might be applied to the output layer as it provides a probability distribution.\n",
    "\n",
    "After obtaining the output, a threshold function is applied to convert continuous values into distinct class labels. In this case, it can be the player's most likely role in the team.\n",
    "\n",
    "## Interpretation and Conclusion\n",
    "\n",
    "The final output provides us with a categorization of each player in our pool. By examining the predicted class labels and the associated probabilities, we can:\n",
    "* Identify which role or position each player is most suited for.\n",
    "* Select the top players for each role to form our optimal team.\n",
    "\n",
    "It's worth noting that the \"optimal\" team is contingent on the data provided and the neural network's training. For better results, the model should be regularly trained with updated data, and other external factors (like team chemistry and current form) should also be considered in real-world scenarios. For our optimal team we defined some weights based on each player position that will take into account the 2 most important stats for each position according to our criteria. See Definig player types bellow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defining Player types    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5 center\n",
    "\theight = 0.5\n",
    "\tweight = 0.5\n",
    "\n",
    "4 forward\n",
    "\tnet_rating = 0.6\n",
    "\treb = 0.4\n",
    "\n",
    "3 small forward\n",
    "\tast_pct = 0.3\n",
    "\tusg_pct = 0.7\n",
    "\n",
    "2 guard\n",
    "\tpts = 0.8\n",
    "\tts_pct = 0.2\n",
    "\n",
    "1 point guard\n",
    "\tast = 0.8\n",
    "\tgp = 0.2\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the DataFrame:\n",
      "   Unnamed: 0        player_name team_abbreviation   age  player_height  \\\n",
      "0           0      Dennis Rodman               CHI  36.0         198.12   \n",
      "1           1  Dwayne Schintzius               LAC  28.0         215.90   \n",
      "2           2       Earl Cureton               TOR  39.0         205.74   \n",
      "3           3        Ed O'Bannon               DAL  24.0         203.20   \n",
      "4           4        Ed Pinckney               MIA  34.0         205.74   \n",
      "\n",
      "   player_weight                      college country draft_year draft_round  \\\n",
      "0      99.790240  Southeastern Oklahoma State     USA       1986           2   \n",
      "1     117.933920                      Florida     USA       1990           1   \n",
      "2      95.254320                Detroit Mercy     USA       1979           3   \n",
      "3     100.697424                         UCLA     USA       1995           1   \n",
      "4     108.862080                    Villanova     USA       1985           1   \n",
      "\n",
      "   ...  pts   reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
      "0  ...  5.7  16.1  3.1        16.1     0.186     0.323    0.100   0.479   \n",
      "1  ...  2.3   1.5  0.3        12.3     0.078     0.151    0.175   0.430   \n",
      "2  ...  0.8   1.0  0.4        -2.1     0.105     0.102    0.103   0.376   \n",
      "3  ...  3.7   2.3  0.6        -8.7     0.060     0.149    0.167   0.399   \n",
      "4  ...  2.4   2.4  0.2       -11.2     0.109     0.179    0.127   0.611   \n",
      "\n",
      "   ast_pct   season  \n",
      "0    0.113  1996-97  \n",
      "1    0.048  1996-97  \n",
      "2    0.148  1996-97  \n",
      "3    0.077  1996-97  \n",
      "4    0.040  1996-97  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Tail of the DataFrame:\n",
      "       Unnamed: 0      player_name team_abbreviation   age  player_height  \\\n",
      "12300       12300  Markieff Morris               MIA  32.0         205.74   \n",
      "12301       12301   Markelle Fultz               ORL  24.0         193.04   \n",
      "12302       12302     Marcus Smart               BOS  28.0         193.04   \n",
      "12303       12303   Marcus Garrett               MIA  23.0         195.58   \n",
      "12304       12304     Micah Potter               DET  24.0         208.28   \n",
      "\n",
      "       player_weight         college country draft_year draft_round  ...  \\\n",
      "12300     111.130040          Kansas     USA       2011           1  ...   \n",
      "12301      94.800728      Washington     USA       2017           1  ...   \n",
      "12302      99.790240  Oklahoma State     USA       2014           1  ...   \n",
      "12303      92.986360          Kansas     USA  Undrafted   Undrafted  ...   \n",
      "12304     112.490816       Wisconsin     USA  Undrafted   Undrafted  ...   \n",
      "\n",
      "        pts  reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
      "12300   7.6  2.6  1.4         4.5     0.059     0.089    0.197   0.547   \n",
      "12301  10.8  2.7  5.5        -5.3     0.010     0.116    0.265   0.517   \n",
      "12302  12.1  3.8  5.9         9.3     0.018     0.093    0.179   0.540   \n",
      "12303   1.1  1.9  0.6         5.8     0.072     0.108    0.086   0.280   \n",
      "12304   4.0  3.0  0.0       -56.4     0.095     0.125    0.148   0.505   \n",
      "\n",
      "       ast_pct   season  \n",
      "12300    0.116  2021-22  \n",
      "12301    0.448  2021-22  \n",
      "12302    0.245  2021-22  \n",
      "12303    0.069  2021-22  \n",
      "12304    0.000  2021-22  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the file path\n",
    "file_path = \"all_seasons.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the head (first few rows) of the DataFrame\n",
    "print(\"Head of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the tail (last few rows) of the DataFrame\n",
    "print(\"\\nTail of the DataFrame:\")\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.936\n",
      "24.976000000000003\n",
      "120.4\n",
      "12.032000000000002\n",
      "9.368\n"
     ]
    }
   ],
   "source": [
    "# Defining target stats based on player types\n",
    "\n",
    "# Point Guard: ast = 0.6, ast = 0.4\n",
    "MAXIMUM_ASSIST_PG = max(df['ast']) * 0.6\n",
    "MAXIMUM_ASSIST_PCTG = max(df['ast_pct']) * 0.4\n",
    "\n",
    "# The target stats will be 80% of the maximum value (it will be really hard to get 100% all the time since we are going to only use 100 players out of the whole dataset)\n",
    "TARGET_POINT_GUARD_VALUE = (MAXIMUM_ASSIST_PG + MAXIMUM_ASSIST_PCTG) * 0.8\n",
    "\n",
    "# Shooting Guard: pts = 0.8, ast = 0.2\n",
    "MAXIMUM_PTS = max(df['pts']) * 0.8\n",
    "MAXIMUM_ASSIST_SG = max(df['ast']) * 0.2\n",
    "\n",
    "# The target stats will be 80% of the maximum value (it will be really hard to get 100% all the time since we are going to only use 100 players out of the whole dataset)\n",
    "TARGET_SHOOTING_GUARD_VALUE = (MAXIMUM_ASSIST_SG + MAXIMUM_PTS) * 0.8\n",
    "\n",
    "\n",
    "# Small Forward: net_rating = 0.5 usg_pct = 0.5\n",
    "MAXIMUM_NET_RATING = max(df['net_rating']) * 0.5\n",
    "MAXIMUM_USG_PCT = max(df['usg_pct']) * 0.5\n",
    "\n",
    "# The target stats will be 80% of the maximum value (it will be really hard to get 100% all the time since we are going to only use 100 players out of the whole dataset)\n",
    "TARGET_SMALL_FORWARD_VALUE = (MAXIMUM_NET_RATING + MAXIMUM_USG_PCT) * 0.8\n",
    "\n",
    "# Forward: pts = 0.4 oreb_pct = 0.6\n",
    "MAXIMUM_PTS_FORWARD = max(df['pts']) * 0.4\n",
    "MAXIMUM_OREB_PCT = max(df['oreb_pct']) * 0.6\n",
    "\n",
    "# The target stats will be 80% of the maximum value (it will be really hard to get 100% all the time since we are going to only use 100 players out of the whole dataset)\n",
    "TARGET_FORWARD_VALUE = (MAXIMUM_PTS_FORWARD + MAXIMUM_OREB_PCT) * 0.8\n",
    "\n",
    "# Center: reb = 0.7 dreb_pct = 0.3 \n",
    "MAXIMUM_REB = max(df['reb']) * 0.7\n",
    "MAXIMUM_DREB_PCT = max(df['dreb_pct']) * 0.3\n",
    "\n",
    "# The target stats will be 80% of the maximum value (it will be really hard to get 100% all the time since we are going to only use 100 players out of the whole dataset)\n",
    "TARGET_CENTER_VALUE = (MAXIMUM_REB + MAXIMUM_DREB_PCT) * 0.8\n",
    "\n",
    "print(TARGET_POINT_GUARD_VALUE)\n",
    "print(TARGET_SHOOTING_GUARD_VALUE)\n",
    "print(TARGET_SMALL_FORWARD_VALUE)\n",
    "print(TARGET_FORWARD_VALUE)\n",
    "print(TARGET_CENTER_VALUE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0       player_name team_abbreviation   age  player_height  \\\n",
      "327         327     Tom Gugliotta               MIN  27.0         208.28   \n",
      "57           57  Hot Rod Williams               PHX  34.0         210.82   \n",
      "12           12     Emanual Davis               HOU  28.0         195.58   \n",
      "379         379      Jud Buechler               CHI  29.0         198.12   \n",
      "140         140    Aaron Williams               VAN  25.0         205.74   \n",
      "..          ...               ...               ...   ...            ...   \n",
      "435         435      Martin Lewis               TOR  22.0         198.12   \n",
      "358         358       Kenny Smith               DEN  32.0         190.50   \n",
      "236         236    Sedale Threatt               HOU  35.0         187.96   \n",
      "363         363     Jimmy Carruth               MIL  27.0         208.28   \n",
      "138         138        A.C. Green               DAL  33.0         205.74   \n",
      "\n",
      "     player_weight                          college country  draft_year  \\\n",
      "327     108.862080             North Carolina State     USA        1996   \n",
      "57      111.130040                           Tulane     USA        1996   \n",
      "12       87.996848                   Delaware State     USA        1996   \n",
      "379     103.418976                          Arizona     USA        1996   \n",
      "140     102.058200                           Xavier     USA        1996   \n",
      "..             ...                              ...     ...         ...   \n",
      "435     102.058200  Seward County Community College     USA        1996   \n",
      "358      77.110640                   North Carolina     USA        1996   \n",
      "236      83.914520               West Virginia Tech     USA        1996   \n",
      "363     120.201880                    Virginia Tech     USA        1996   \n",
      "138     102.058200                     Oregon State     USA        1996   \n",
      "\n",
      "    draft_round  ...   pts  reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  \\\n",
      "327           1  ...  20.6  8.7  4.1        -2.0     0.072     0.193    0.277   \n",
      "57            2  ...   8.0  8.3  1.5         4.3     0.099     0.199    0.122   \n",
      "12    Undrafted  ...   5.0  1.7  2.0         6.6     0.011     0.098    0.144   \n",
      "379           2  ...   1.8  1.7  0.8         5.4     0.070     0.121    0.120   \n",
      "140   Undrafted  ...   6.2  4.3  0.5        -8.3     0.129     0.163    0.168   \n",
      "..          ...  ...   ...  ...  ...         ...       ...       ...      ...   \n",
      "435           2  ...   1.6  0.7  0.4        -3.5     0.087     0.045    0.135   \n",
      "358           1  ...   6.3  0.9  2.4       -14.2     0.006     0.058    0.194   \n",
      "236           6  ...   3.3  1.1  1.9        -3.5     0.017     0.063    0.122   \n",
      "363   Undrafted  ...   1.3  1.0  0.0       -17.7     0.000     0.211    0.103   \n",
      "138           1  ...   7.2  7.9  0.8        -8.0     0.100     0.207    0.119   \n",
      "\n",
      "     ts_pct  ast_pct   season  \n",
      "327   0.526    0.194  1996-97  \n",
      "57    0.538    0.067  1996-97  \n",
      "12    0.565    0.191  1996-97  \n",
      "379   0.423    0.121  1996-97  \n",
      "140   0.599    0.051  1996-97  \n",
      "..      ...      ...      ...  \n",
      "435   0.470    0.125  1996-97  \n",
      "358   0.580    0.262  1996-97  \n",
      "236   0.451    0.185  1996-97  \n",
      "363   0.727    0.000  1996-97  \n",
      "138   0.523    0.045  1996-97  \n",
      "\n",
      "[100 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "df['draft_year'] = df['season'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# Define the target year and the window size\n",
    "target_year = 1996  # Replace with your desired target year\n",
    "window_size = 5\n",
    "\n",
    "# Calculate the start and end years of the window\n",
    "start_year = target_year - window_size\n",
    "end_year = target_year\n",
    "\n",
    "# Filter the dataset to include only records within the 5-year window\n",
    "filtered_df = df[(df['draft_year'] >= start_year) & (df['draft_year'] <= end_year)]\n",
    "\n",
    "# Ensure the filtered dataset has at least 100 players\n",
    "if len(filtered_df) < 100:\n",
    "    print(\"There are not enough players within the specified window.\")\n",
    "else:\n",
    "    # Randomly select 100 players from the filtered dataset\n",
    "    random.seed(42)  # Set a random seed for reproducibility\n",
    "    selected_players = random.sample(range(len(filtered_df)), 100)\n",
    "\n",
    "    # Create a DataFrame containing the selected players\n",
    "    selected_df = filtered_df.iloc[selected_players]\n",
    "\n",
    "    # Display the selected players\n",
    "    print(selected_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.3268 - accuracy: 0.8781\n",
      "Epoch 2/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.1036 - accuracy: 0.9593\n",
      "Epoch 3/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.1043 - accuracy: 0.9563\n",
      "Epoch 4/50\n",
      "385/385 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9605\n",
      "Epoch 5/50\n",
      "385/385 [==============================] - 1s 3ms/step - loss: 0.0893 - accuracy: 0.9638\n",
      "Epoch 6/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0817 - accuracy: 0.9668\n",
      "Epoch 7/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0865 - accuracy: 0.9628\n",
      "Epoch 8/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0701 - accuracy: 0.9703\n",
      "Epoch 9/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.9695\n",
      "Epoch 10/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0707 - accuracy: 0.9711\n",
      "Epoch 11/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0894 - accuracy: 0.9670\n",
      "Epoch 12/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0666 - accuracy: 0.9716\n",
      "Epoch 13/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0674 - accuracy: 0.9732\n",
      "Epoch 14/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0678 - accuracy: 0.9708\n",
      "Epoch 15/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0731 - accuracy: 0.9705\n",
      "Epoch 16/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0594 - accuracy: 0.9765\n",
      "Epoch 17/50\n",
      "385/385 [==============================] - 1s 3ms/step - loss: 0.0673 - accuracy: 0.9715\n",
      "Epoch 18/50\n",
      "385/385 [==============================] - 1s 3ms/step - loss: 0.0569 - accuracy: 0.9759\n",
      "Epoch 19/50\n",
      "385/385 [==============================] - 1s 3ms/step - loss: 0.0738 - accuracy: 0.9707\n",
      "Epoch 20/50\n",
      "385/385 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.9781\n",
      "Epoch 21/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0591 - accuracy: 0.9745\n",
      "Epoch 22/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0529 - accuracy: 0.9787\n",
      "Epoch 23/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0612 - accuracy: 0.9749\n",
      "Epoch 24/50\n",
      "385/385 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9776\n",
      "Epoch 25/50\n",
      "385/385 [==============================] - 1s 3ms/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 26/50\n",
      "385/385 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9783\n",
      "Epoch 27/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0510 - accuracy: 0.9795\n",
      "Epoch 28/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0553 - accuracy: 0.9760\n",
      "Epoch 29/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0550 - accuracy: 0.9781\n",
      "Epoch 30/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0501 - accuracy: 0.9785\n",
      "Epoch 31/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0458 - accuracy: 0.9804\n",
      "Epoch 32/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0541 - accuracy: 0.9765\n",
      "Epoch 33/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.9789\n",
      "Epoch 34/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0611 - accuracy: 0.9750\n",
      "Epoch 35/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0485 - accuracy: 0.9810\n",
      "Epoch 36/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0461 - accuracy: 0.9820\n",
      "Epoch 37/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0532 - accuracy: 0.9790\n",
      "Epoch 38/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0461 - accuracy: 0.9794\n",
      "Epoch 39/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0525 - accuracy: 0.9777\n",
      "Epoch 40/50\n",
      "385/385 [==============================] - 1s 4ms/step - loss: 0.0453 - accuracy: 0.9810\n",
      "Epoch 41/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0488 - accuracy: 0.9805\n",
      "Epoch 42/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0452 - accuracy: 0.9820\n",
      "Epoch 43/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0449 - accuracy: 0.9807\n",
      "Epoch 44/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0412 - accuracy: 0.9823\n",
      "Epoch 45/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0455 - accuracy: 0.9818\n",
      "Epoch 46/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0423 - accuracy: 0.9831\n",
      "Epoch 47/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0449 - accuracy: 0.9808\n",
      "Epoch 48/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0428 - accuracy: 0.9833\n",
      "Epoch 49/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0429 - accuracy: 0.9814\n",
      "Epoch 50/50\n",
      "385/385 [==============================] - 2s 4ms/step - loss: 0.0420 - accuracy: 0.9829\n",
      "INFO:tensorflow:Assets written to: player_type_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: player_type_model\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(8,)),  # 8 input features\n",
    "    keras.layers.Dense(64, activation='relu'),  # First hidden layer with 64 neurons and ReLU activation\n",
    "    keras.layers.Dense(64, activation='relu'),  # Second hidden layer with 64 neurons and ReLU activation\n",
    "    keras.layers.Dense(64, activation='relu'),  # Third hidden layer with 64 neurons and ReLU activation\n",
    "    keras.layers.Dense(64, activation='relu'),  # Fourth hidden layer with 64 neurons and ReLU activation\n",
    "    keras.layers.Dense(64, activation='relu'),  # Fifth hidden layer with 64 neurons and ReLU activation\n",
    "    keras.layers.Dense(5, activation='softmax')   # Output layer with 5 nodes (one for each player type)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_input_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\josh\\Documents\\CST435\\NBA.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/josh/Documents/CST435/NBA.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39mplayer_type_model\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/josh/Documents/CST435/NBA.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Replace 'new_input_features' with your new input data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/josh/Documents/CST435/NBA.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m new_input_features \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(new_input_features)  \u001b[39m# Normalize the new input data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/josh/Documents/CST435/NBA.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(new_input_features)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_input_features' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
