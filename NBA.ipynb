{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network: NBA Player Dataset Team Optimazitation\n",
    "\n",
    "## Team\n",
    "\n",
    "Gabriel Aracena\n",
    "Joshua Canode\n",
    "Aaron Galicia\n",
    "\n",
    "### Project Description\n",
    "\n",
    "Select a pool of 100 players from the data set, within a 5-year window.\n",
    "Define \"optimal team\" based on your decision of the player characteristics necessary to build a team. For example, if all 5 players are 3-point shooters, the team will miss defenders, which will make it unbalanced.\n",
    "Your task is to identify the optimal team of 5 players from that pool.\n",
    "Examine the multilayer neural network MLP architecture depicted in the \"CST-435 An Artificial Neural Network Model Image.\"\n",
    "Build a deep artificial neural network MLP to include the following: a) 1 input layer, b) as many hidden layers as you deem necessary, and c) an output layer fully connected to the hidden layers.\n",
    "Explain your architecture and how the basketball player characteristics are used as inputs.\n",
    "Activate the MLP by performing the following steps:\n",
    "\n",
    "Starting at the input layer, forward propagate the patterns of the training data through the network to generate an output.\n",
    "Based on the network's output, calculate the error that we want to minimize using a cost function that we will describe later.\n",
    "Backpropagate the error, find its derivative with respect to each weight in the network, and update the model.\n",
    "Repeat steps 1 through 3 for multiple epochs and learn the weights of the MLP.\n",
    "Use forward propagation to calculate the network output and apply a threshold function to obtain the predicted class labels in the one-hot representation.\n",
    "Interpret the output of your MLP in the context of selecting an optimal basketball team.\n",
    "\n",
    "## Abstract\n",
    "\n",
    "The objective is to use a deep artificial neural network (ANN) to determine an optimal team composition from a pool of basketball players. Given player characteristics, we want to identify the best five players that result in a balanced team.\n",
    "\n",
    "### Data Preparation:\n",
    "\n",
    "* Load the NBA Players Dataset.\n",
    "* Filter to get a pool of 100 players from a random 5-year window.\n",
    "* Normalize/Standardize player characteristics.\n",
    "\n",
    "### ANN Model Building:\n",
    "\n",
    "* Design a Multi-layer Perceptron (MLP) based on the architecture of the CST-435 An Artificial Neural Network Model Image (see below)\n",
    "* Define layers: Input layer, Hidden layers, and Output layer.\n",
    "* Determine the appropriate activation function, optimizer, and loss function for the MLP.\n",
    "\n",
    "![ANNModel](ANNModel.png)\n",
    "\n",
    "### Training the ANN:\n",
    "\n",
    "* Forward propagation: Use player characteristics to propagate input data through the network and generate an output.\n",
    "* Calculate the error using a predefined cost function.\n",
    "* Backpropagate the error to update model weights.\n",
    "* Repeat the above steps for several epochs.\n",
    "\n",
    "### Evaluation and Team Selection:\n",
    "\n",
    "* Use forward propagation on the trained ANN to predict player effectiveness or class labels.\n",
    "* Apply a threshold function to these predictions.\n",
    "* Select the top five players that meet the optimal team criteria.\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "* Input Layer: This layer will have neurons equal to the number of player characteristics we're considering (e.g. points, assists, offensive rebounds, defensive rebounds,etc.).\n",
    "* Hidden Layers: Multiple hidden layers can be used to capture intricate patterns and relationships. We initially thought we would do 5 hidden layers, one for each position,  but we decided to stick with only a single layer for simplicity and might change that later. \n",
    "* Output Layer: This layer can have neurons equal to the number of classes or roles in the team we're predicting for (e.g., point guard, shooting guard, center, etc.). Each neuron will give the likelihood of a player fitting that role.\n",
    "\n",
    "## Activation and Threshold Function\n",
    "\n",
    "During forward propagation, each neuron processes input data and transmits it to the next layer. An activation function is applied to this data. For this model, we can use the ReLU (Rectified Linear Unit) activation function for hidden layers due to its computational efficiency and the ability to handle non-linearities. The softmax function might be applied to the output layer as it provides a probability distribution.\n",
    "\n",
    "After obtaining the output, a threshold function is applied to convert continuous values into distinct class labels. In this case, it can be the player's most likely role in the team.\n",
    "\n",
    "## Interpretation and Conclusion\n",
    "\n",
    "The final output provides us with a categorization of each player in our pool. By examining the predicted class labels and the associated probabilities, we can:\n",
    "* Identify which role or position each player is most suited for.\n",
    "* Select the top players for each role to form our optimal team.\n",
    "\n",
    "We are going to define target values for each position and use hope to use that in the end of each training to classify if the output team was good or not. \n",
    "\n",
    "It's worth noting that the \"optimal\" team is contingent on the data provided and the neural network's training. For better results, the model should be regularly trained with updated data, and other external factors (like team chemistry and current form) should also be considered in real-world scenarios. For our optimal team we defined some weights based on each player position that will take into account the 2 most important stats for each position according to our criteria. See Definig player types bellow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defining Player types    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n5 center\\n\\theight = 0.5\\n\\tweight = 0.5\\n\\n4 forward\\n\\tnet_rating = 0.6\\n\\treb = 0.4\\n\\n3 small forward\\n\\tast_pct = 0.3\\n\\tusg_pct = 0.7\\n\\n2 guard\\n\\tpts = 0.8\\n\\tts_pct = 0.2\\n\\n1 point guard\\n\\tast = 0.8\\n\\tgp = 0.2\\n\\n\\n'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "5 center\n",
    "\theight = 0.5\n",
    "\tweight = 0.5\n",
    "\n",
    "4 forward\n",
    "\tnet_rating = 0.6\n",
    "\treb = 0.4\n",
    "\n",
    "3 small forward\n",
    "\tast_pct = 0.3\n",
    "\tusg_pct = 0.7\n",
    "\n",
    "2 guard\n",
    "\tpts = 0.8\n",
    "\tts_pct = 0.2\n",
    "\n",
    "1 point guard\n",
    "\tast = 0.8\n",
    "\tgp = 0.2\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the DataFrame:\n",
      "   Unnamed: 0        player_name team_abbreviation   age  player_height  \\\n",
      "0           0      Dennis Rodman               CHI  36.0         198.12   \n",
      "1           1  Dwayne Schintzius               LAC  28.0         215.90   \n",
      "2           2       Earl Cureton               TOR  39.0         205.74   \n",
      "3           3        Ed O'Bannon               DAL  24.0         203.20   \n",
      "4           4        Ed Pinckney               MIA  34.0         205.74   \n",
      "\n",
      "   player_weight                      college country draft_year draft_round  \\\n",
      "0      99.790240  Southeastern Oklahoma State     USA       1986           2   \n",
      "1     117.933920                      Florida     USA       1990           1   \n",
      "2      95.254320                Detroit Mercy     USA       1979           3   \n",
      "3     100.697424                         UCLA     USA       1995           1   \n",
      "4     108.862080                    Villanova     USA       1985           1   \n",
      "\n",
      "   ...  pts   reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
      "0  ...  5.7  16.1  3.1        16.1     0.186     0.323    0.100   0.479   \n",
      "1  ...  2.3   1.5  0.3        12.3     0.078     0.151    0.175   0.430   \n",
      "2  ...  0.8   1.0  0.4        -2.1     0.105     0.102    0.103   0.376   \n",
      "3  ...  3.7   2.3  0.6        -8.7     0.060     0.149    0.167   0.399   \n",
      "4  ...  2.4   2.4  0.2       -11.2     0.109     0.179    0.127   0.611   \n",
      "\n",
      "   ast_pct   season  \n",
      "0    0.113  1996-97  \n",
      "1    0.048  1996-97  \n",
      "2    0.148  1996-97  \n",
      "3    0.077  1996-97  \n",
      "4    0.040  1996-97  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Tail of the DataFrame:\n",
      "       Unnamed: 0      player_name team_abbreviation   age  player_height  \\\n",
      "12300       12300  Markieff Morris               MIA  32.0         205.74   \n",
      "12301       12301   Markelle Fultz               ORL  24.0         193.04   \n",
      "12302       12302     Marcus Smart               BOS  28.0         193.04   \n",
      "12303       12303   Marcus Garrett               MIA  23.0         195.58   \n",
      "12304       12304     Micah Potter               DET  24.0         208.28   \n",
      "\n",
      "       player_weight         college country draft_year draft_round  ...  \\\n",
      "12300     111.130040          Kansas     USA       2011           1  ...   \n",
      "12301      94.800728      Washington     USA       2017           1  ...   \n",
      "12302      99.790240  Oklahoma State     USA       2014           1  ...   \n",
      "12303      92.986360          Kansas     USA  Undrafted   Undrafted  ...   \n",
      "12304     112.490816       Wisconsin     USA  Undrafted   Undrafted  ...   \n",
      "\n",
      "        pts  reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
      "12300   7.6  2.6  1.4         4.5     0.059     0.089    0.197   0.547   \n",
      "12301  10.8  2.7  5.5        -5.3     0.010     0.116    0.265   0.517   \n",
      "12302  12.1  3.8  5.9         9.3     0.018     0.093    0.179   0.540   \n",
      "12303   1.1  1.9  0.6         5.8     0.072     0.108    0.086   0.280   \n",
      "12304   4.0  3.0  0.0       -56.4     0.095     0.125    0.148   0.505   \n",
      "\n",
      "       ast_pct   season  \n",
      "12300    0.116  2021-22  \n",
      "12301    0.448  2021-22  \n",
      "12302    0.245  2021-22  \n",
      "12303    0.069  2021-22  \n",
      "12304    0.000  2021-22  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the file path\n",
    "file_path = \"all_seasons.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the head (first few rows) of the DataFrame\n",
    "print(\"Head of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the tail (last few rows) of the DataFrame\n",
    "print(\"\\nTail of the DataFrame:\")\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0263600000000002\n",
      "1.02918\n",
      "1.001\n",
      "1.1804000000000001\n",
      "1.204001248\n"
     ]
    }
   ],
   "source": [
    "# Defining target stats based on player types\n",
    "\n",
    "PROPORTINALITY_FACTOR = 1000\n",
    "\n",
    "def calculateTargetValue(position, stat1, stat2):\n",
    "    # Point Guard: ast = 0.8 gp = 0.2\n",
    "    # Shooting Guard: pts = 0.8 ts_pct = 0.2\n",
    "    if (position == 1 or position == 2):\n",
    "        weightedValue = ((stat1 + PROPORTINALITY_FACTOR) * 0.8 + (stat2 + PROPORTINALITY_FACTOR) * 0.2 ) / PROPORTINALITY_FACTOR\n",
    "        return weightedValue\n",
    "    \n",
    "    # Small Forward: ast_pct = 0.3 usg_pct = 0.7\n",
    "    elif (position == 3):\n",
    "        weightedValue = ((stat1 + PROPORTINALITY_FACTOR) * 0.3 + (stat2 + PROPORTINALITY_FACTOR) * 0.7 ) / PROPORTINALITY_FACTOR\n",
    "        return weightedValue\n",
    "    # Forward: net_rating = 0.6 reb = 0.4\n",
    "    elif (position == 4):\n",
    "        weightedValue = ((stat1 + PROPORTINALITY_FACTOR) * 0.6 + (stat2 + PROPORTINALITY_FACTOR) * 0.4 ) / PROPORTINALITY_FACTOR\n",
    "        return weightedValue\n",
    "    # Center: height = 0.5 weight = 0.5\n",
    "    elif (position == 5):\n",
    "        weightedValue = ((stat1 + PROPORTINALITY_FACTOR) * 0.6 + (stat2 + PROPORTINALITY_FACTOR) * 0.4 ) / PROPORTINALITY_FACTOR\n",
    "        return weightedValue\n",
    "\n",
    "MAXIMUM_ASSIST = max(df['ast'])\n",
    "MAXIMUM_GP = max(df['gp'])\n",
    "MAXIMUM_PTS = max(df['pts'])\n",
    "MAXIMUM_SHOOTING_RATE = max(df['ts_pct'])\n",
    "MAXIMUM_ASSIST_PCTG = max(df['ast_pct'])\n",
    "MAXIMUM_USG_PCT = max(df['usg_pct']) \n",
    "MAXIMUM_NET_RATING = max(df['net_rating'])\n",
    "MAXIMUM_REB = max(df['oreb_pct'])\n",
    "MAXIMUM_HEIGHT = max(df['player_height']) \n",
    "MAXIMUM_WEIGHT = max(df['player_weight']) \n",
    "\n",
    "# The target stats will be 80% of the maximum value (it will be really hard to get 100% all the time since we are going to only use 100 players out of the whole dataset)\n",
    "TARGET_POINT_GUARD_VALUE = calculateTargetValue(1, MAXIMUM_ASSIST, MAXIMUM_GP)\n",
    "TARGET_SHOOTING_GUARD_VALUE = calculateTargetValue(2, MAXIMUM_PTS, MAXIMUM_SHOOTING_RATE)\n",
    "TARGET_SMALL_FORWARD_VALUE = calculateTargetValue(3, MAXIMUM_ASSIST_PCTG, MAXIMUM_USG_PCT)\n",
    "TARGET_FORWARD_VALUE = calculateTargetValue(4, MAXIMUM_NET_RATING, MAXIMUM_REB)\n",
    "TARGET_CENTER_VALUE = calculateTargetValue(5, MAXIMUM_HEIGHT, MAXIMUM_WEIGHT)\n",
    "\n",
    "print(TARGET_POINT_GUARD_VALUE)\n",
    "print(TARGET_SHOOTING_GUARD_VALUE)\n",
    "print(TARGET_SMALL_FORWARD_VALUE)\n",
    "print(TARGET_FORWARD_VALUE)\n",
    "print(TARGET_CENTER_VALUE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0        player_name team_abbreviation   age  player_height  \\\n",
      "0            0      Dennis Rodman               CHI  36.0         198.12   \n",
      "1            1  Dwayne Schintzius               LAC  28.0         215.90   \n",
      "2            2       Earl Cureton               TOR  39.0         205.74   \n",
      "3            3        Ed O'Bannon               DAL  24.0         203.20   \n",
      "4            4        Ed Pinckney               MIA  34.0         205.74   \n",
      "..         ...                ...               ...   ...            ...   \n",
      "95          95     Glenn Robinson               MIL  24.0         200.66   \n",
      "96          96         Grant Long               DET  31.0         205.74   \n",
      "97          97      Greg Anderson               SAS  33.0         208.28   \n",
      "98          98       Greg Anthony               VAN  29.0         185.42   \n",
      "99          99      Greg Dreiling               DAL  33.0         215.90   \n",
      "\n",
      "    player_weight                      college country  draft_year  \\\n",
      "0       99.790240  Southeastern Oklahoma State     USA        1996   \n",
      "1      117.933920                      Florida     USA        1996   \n",
      "2       95.254320                Detroit Mercy     USA        1996   \n",
      "3      100.697424                         UCLA     USA        1996   \n",
      "4      108.862080                    Villanova     USA        1996   \n",
      "..            ...                          ...     ...         ...   \n",
      "95     106.594120                       Purdue     USA        1996   \n",
      "96     112.490816             Eastern Michigan     USA        1996   \n",
      "97     113.398000                      Houston     USA        1996   \n",
      "98      81.646560             Nevada-Las Vegas     USA        1996   \n",
      "99     120.201880                       Kansas     USA        1996   \n",
      "\n",
      "   draft_round  ...   pts   reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  \\\n",
      "0            2  ...   5.7  16.1  3.1        16.1     0.186     0.323    0.100   \n",
      "1            1  ...   2.3   1.5  0.3        12.3     0.078     0.151    0.175   \n",
      "2            3  ...   0.8   1.0  0.4        -2.1     0.105     0.102    0.103   \n",
      "3            1  ...   3.7   2.3  0.6        -8.7     0.060     0.149    0.167   \n",
      "4            1  ...   2.4   2.4  0.2       -11.2     0.109     0.179    0.127   \n",
      "..         ...  ...   ...   ...  ...         ...       ...       ...      ...   \n",
      "95           1  ...  21.1   6.3  3.1        -2.9     0.051     0.144    0.278   \n",
      "96           2  ...   5.0   3.4  0.6         4.0     0.096     0.150    0.154   \n",
      "97           1  ...   3.9   5.5  0.4       -14.2     0.109     0.219    0.106   \n",
      "98           1  ...   9.5   2.8  6.3        -9.4     0.015     0.099    0.177   \n",
      "99           2  ...   2.0   1.9  0.3        -8.0     0.059     0.192    0.114   \n",
      "\n",
      "    ts_pct  ast_pct   season  \n",
      "0    0.479    0.113  1996-97  \n",
      "1    0.430    0.048  1996-97  \n",
      "2    0.376    0.148  1996-97  \n",
      "3    0.399    0.077  1996-97  \n",
      "4    0.611    0.040  1996-97  \n",
      "..     ...      ...      ...  \n",
      "95   0.528    0.146  1996-97  \n",
      "96   0.523    0.058  1996-97  \n",
      "97   0.531    0.033  1996-97  \n",
      "98   0.526    0.358  1996-97  \n",
      "99   0.466    0.048  1996-97  \n",
      "\n",
      "[100 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "df['draft_year'] = df['season'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# Define the target year and the window size\n",
    "enough_players = False\n",
    "window_size = 5\n",
    "while not enough_players:\n",
    "    target_year = 2000 # random.randint(min(df['draft_year']), max(df['draft_year']))\n",
    "    start_year = target_year - window_size\n",
    "    end_year = target_year\n",
    "    filtered_df = df[(df['draft_year'] >= start_year) & (df['draft_year'] <= end_year)]\n",
    "    \n",
    "    if len(filtered_df) >= 100:\n",
    "        enough_players = True\n",
    "        selected_df = filtered_df.head(100)\n",
    "        '''random.seed(42)\n",
    "        selected_players = random.sample(range(len(filtered_df)), 100)\n",
    "        selected_df = filtered_df.iloc[selected_players]\n",
    "        '''\n",
    "        print(selected_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 141.1515\n",
      "Epoch 2/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 139.7158\n",
      "Epoch 3/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6788\n",
      "Epoch 4/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6695\n",
      "Epoch 5/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6658\n",
      "Epoch 6/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6641\n",
      "Epoch 7/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6629\n",
      "Epoch 8/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6624\n",
      "Epoch 9/100\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 139.6620\n",
      "Epoch 10/100\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 139.6618\n",
      "Epoch 11/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6615\n",
      "Epoch 12/100\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 139.6614\n",
      "Epoch 13/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6613\n",
      "Epoch 14/100\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 139.6612\n",
      "Epoch 15/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6611\n",
      "Epoch 16/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6611\n",
      "Epoch 17/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 18/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6611\n",
      "Epoch 19/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 139.6610\n",
      "Epoch 20/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 21/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6611\n",
      "Epoch 22/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 23/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 24/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 25/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 26/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 27/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 28/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 29/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 30/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 31/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 32/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 33/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 34/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 35/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 36/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 37/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 38/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 39/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 40/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 41/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 42/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 43/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 44/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 45/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 46/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 47/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 48/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 49/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 50/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 51/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 52/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 53/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 54/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 55/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 56/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 57/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 58/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 59/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 60/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 61/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 62/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 63/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 64/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 65/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 66/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 67/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 68/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 69/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 70/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 71/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 72/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 73/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 74/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 75/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 76/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 77/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 78/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 79/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 80/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 81/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 82/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 83/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 84/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 85/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 86/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 87/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 88/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 89/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 90/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 91/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 92/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 93/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 94/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 95/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 96/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6611\n",
      "Epoch 97/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 98/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 99/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6610\n",
      "Epoch 100/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 139.6609\n",
      "Epoch 1/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 52.0919\n",
      "Epoch 2/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.3072\n",
      "Epoch 3/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2851\n",
      "Epoch 4/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2796\n",
      "Epoch 5/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2775\n",
      "Epoch 6/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2764\n",
      "Epoch 7/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2758\n",
      "Epoch 8/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2755\n",
      "Epoch 9/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2753\n",
      "Epoch 10/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2751\n",
      "Epoch 11/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2750\n",
      "Epoch 12/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2750\n",
      "Epoch 13/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2749\n",
      "Epoch 14/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2749\n",
      "Epoch 15/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 16/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 17/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 18/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 19/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 20/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 21/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 22/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 23/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 24/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 25/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 26/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 27/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 28/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 29/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 30/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 31/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 32/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 33/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 34/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 35/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 36/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 37/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 38/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 39/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 40/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 41/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 42/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 43/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 44/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 45/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 46/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 47/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 48/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 49/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 50/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 51/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 52/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 53/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 54/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 55/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 56/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 57/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 58/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 59/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 60/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 61/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 62/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 63/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 64/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 65/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 66/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 67/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 68/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 69/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 70/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 71/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 72/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 73/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 74/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 75/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 76/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 77/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 78/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 79/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 80/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 81/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 82/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 83/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 84/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 85/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 86/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 87/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 88/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 89/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 90/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 91/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 92/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 93/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 94/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 95/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 96/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2747\n",
      "Epoch 97/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 98/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 99/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 100/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 51.2748\n",
      "Epoch 1/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0076\n",
      "Epoch 2/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.3957e-04\n",
      "Epoch 3/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.9689e-04\n",
      "Epoch 4/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1747e-04\n",
      "Epoch 5/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.8749e-05\n",
      "Epoch 6/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.5730e-05\n",
      "Epoch 7/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.1721e-05\n",
      "Epoch 8/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.0191e-05\n",
      "Epoch 9/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.5746e-05\n",
      "Epoch 10/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.9775e-05\n",
      "Epoch 11/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.1057e-05\n",
      "Epoch 12/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.4643e-05\n",
      "Epoch 13/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.1561e-05\n",
      "Epoch 14/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.3578e-05\n",
      "Epoch 15/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.2062e-05\n",
      "Epoch 16/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.9641e-05\n",
      "Epoch 17/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.2738e-05\n",
      "Epoch 18/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.9545e-05\n",
      "Epoch 19/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.5175e-05\n",
      "Epoch 20/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7817e-05\n",
      "Epoch 21/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.8664e-05\n",
      "Epoch 22/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.7655e-05\n",
      "Epoch 23/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1953e-05\n",
      "Epoch 24/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.7273e-05\n",
      "Epoch 25/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.1829e-05\n",
      "Epoch 26/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.3103e-06\n",
      "Epoch 27/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.7270e-05\n",
      "Epoch 28/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.4537e-05\n",
      "Epoch 29/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.1808e-05\n",
      "Epoch 30/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.6533e-05\n",
      "Epoch 31/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2063e-05\n",
      "Epoch 32/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2285e-05\n",
      "Epoch 33/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.0995e-05\n",
      "Epoch 34/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.1461e-06\n",
      "Epoch 35/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.8175e-06\n",
      "Epoch 36/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.5625e-06\n",
      "Epoch 37/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1167e-05\n",
      "Epoch 38/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1810e-05\n",
      "Epoch 39/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.0090e-05\n",
      "Epoch 40/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.7217e-05\n",
      "Epoch 41/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.4719e-05\n",
      "Epoch 42/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.7286e-06\n",
      "Epoch 43/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.3436e-06\n",
      "Epoch 44/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.8983e-06\n",
      "Epoch 45/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.3416e-06\n",
      "Epoch 46/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.0144e-06\n",
      "Epoch 47/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.1863e-06\n",
      "Epoch 48/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.5628e-06\n",
      "Epoch 49/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.8320e-06\n",
      "Epoch 50/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.9669e-06\n",
      "Epoch 51/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.0076e-05\n",
      "Epoch 52/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2888e-05\n",
      "Epoch 53/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.8944e-06\n",
      "Epoch 54/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.5410e-06\n",
      "Epoch 55/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7779e-06\n",
      "Epoch 56/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.2641e-06\n",
      "Epoch 57/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.8233e-06\n",
      "Epoch 58/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.3239e-05\n",
      "Epoch 59/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.3480e-06\n",
      "Epoch 60/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.0750e-06\n",
      "Epoch 61/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.3210e-06\n",
      "Epoch 62/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.1204e-06\n",
      "Epoch 63/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.1337e-06\n",
      "Epoch 64/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.3629e-06\n",
      "Epoch 65/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.5499e-06\n",
      "Epoch 66/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.0255e-06\n",
      "Epoch 67/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.4165e-06\n",
      "Epoch 68/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.2313e-06\n",
      "Epoch 69/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.1372e-06\n",
      "Epoch 70/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.8126e-06\n",
      "Epoch 71/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.2121e-06\n",
      "Epoch 72/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.9476e-06\n",
      "Epoch 73/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.0719e-06\n",
      "Epoch 74/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.2269e-06\n",
      "Epoch 75/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.9970e-06\n",
      "Epoch 76/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.3477e-06\n",
      "Epoch 77/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.8103e-06\n",
      "Epoch 78/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.4130e-06\n",
      "Epoch 79/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.7979e-06\n",
      "Epoch 80/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.8111e-06\n",
      "Epoch 81/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.0969e-06\n",
      "Epoch 82/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.5154e-06\n",
      "Epoch 83/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.3425e-06\n",
      "Epoch 84/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2105e-06\n",
      "Epoch 85/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2830e-06\n",
      "Epoch 86/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.0586e-06\n",
      "Epoch 87/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2529e-06\n",
      "Epoch 88/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.6260e-07\n",
      "Epoch 89/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.8505e-06\n",
      "Epoch 90/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1285e-06\n",
      "Epoch 91/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.3561e-06\n",
      "Epoch 92/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.0200e-06\n",
      "Epoch 93/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.2906e-06\n",
      "Epoch 94/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.8373e-07\n",
      "Epoch 95/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.7102e-06\n",
      "Epoch 96/100\n",
      "382/382 [==============================] - 0s 1ms/step - loss: 3.5136e-06\n",
      "Epoch 97/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.6479e-07\n",
      "Epoch 98/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.5199e-06\n",
      "Epoch 99/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 9.3247e-07\n",
      "Epoch 100/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 1.9450e-06\n",
      "Epoch 1/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 41.9667\n",
      "Epoch 2/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.9998\n",
      "Epoch 3/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8754\n",
      "Epoch 4/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8430\n",
      "Epoch 5/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8292\n",
      "Epoch 6/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8217\n",
      "Epoch 7/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8172\n",
      "Epoch 8/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8143\n",
      "Epoch 9/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8124\n",
      "Epoch 10/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8110\n",
      "Epoch 11/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8100\n",
      "Epoch 12/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8093\n",
      "Epoch 13/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8088\n",
      "Epoch 14/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8084\n",
      "Epoch 15/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8082\n",
      "Epoch 16/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8080\n",
      "Epoch 17/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8078\n",
      "Epoch 18/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8078\n",
      "Epoch 19/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 20/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8079\n",
      "Epoch 21/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8078\n",
      "Epoch 22/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 23/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 24/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 25/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 26/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 27/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 28/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 29/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 30/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8079\n",
      "Epoch 31/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 32/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 33/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 34/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 35/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 36/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 37/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 38/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 39/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 40/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 41/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 42/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 43/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 44/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 45/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 46/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 47/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 48/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 49/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 50/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 51/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 52/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 53/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 54/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 55/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 56/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 57/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 58/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 59/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 60/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 61/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 62/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 63/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 64/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 65/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 66/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 67/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 68/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 69/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 70/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 71/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 72/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 73/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 74/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 75/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 76/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 77/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 78/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 79/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 80/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 81/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 82/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 83/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 84/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 85/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 86/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 87/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 88/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 89/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 90/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 91/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 92/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 93/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 94/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 95/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8077\n",
      "Epoch 96/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 97/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 98/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 99/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 100/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 40.8076\n",
      "Epoch 1/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15467.5859\n",
      "Epoch 2/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.9014\n",
      "Epoch 3/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.4717\n",
      "Epoch 4/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.3594\n",
      "Epoch 5/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.3057\n",
      "Epoch 6/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2949\n",
      "Epoch 7/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2754\n",
      "Epoch 8/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2695\n",
      "Epoch 9/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2617\n",
      "Epoch 10/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2578\n",
      "Epoch 11/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2607\n",
      "Epoch 12/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2568\n",
      "Epoch 13/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2500\n",
      "Epoch 14/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2529\n",
      "Epoch 15/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2607\n",
      "Epoch 16/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2422\n",
      "Epoch 17/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2490\n",
      "Epoch 18/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2480\n",
      "Epoch 19/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2441\n",
      "Epoch 20/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2441\n",
      "Epoch 21/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 22/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2451\n",
      "Epoch 23/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2490\n",
      "Epoch 24/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2480\n",
      "Epoch 25/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2490\n",
      "Epoch 26/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2578\n",
      "Epoch 27/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 28/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2451\n",
      "Epoch 29/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 30/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 31/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 32/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 33/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2480\n",
      "Epoch 34/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 35/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2451\n",
      "Epoch 36/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2480\n",
      "Epoch 37/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2441\n",
      "Epoch 38/100\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 15450.2451\n",
      "Epoch 39/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 40/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2578\n",
      "Epoch 41/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 42/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 43/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2500\n",
      "Epoch 44/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2441\n",
      "Epoch 45/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2451\n",
      "Epoch 46/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 47/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2393\n",
      "Epoch 48/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2422\n",
      "Epoch 49/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 50/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 51/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2451\n",
      "Epoch 52/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2529\n",
      "Epoch 53/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 54/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2539\n",
      "Epoch 55/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2559\n",
      "Epoch 56/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2500\n",
      "Epoch 57/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2480\n",
      "Epoch 58/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2500\n",
      "Epoch 59/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2529\n",
      "Epoch 60/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 61/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 62/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 63/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2354\n",
      "Epoch 64/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2412\n",
      "Epoch 65/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 66/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2500\n",
      "Epoch 67/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 68/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2500\n",
      "Epoch 69/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2500\n",
      "Epoch 70/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 71/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2412\n",
      "Epoch 72/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2441\n",
      "Epoch 73/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2539\n",
      "Epoch 74/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2441\n",
      "Epoch 75/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2559\n",
      "Epoch 76/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2422\n",
      "Epoch 77/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2451\n",
      "Epoch 78/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 79/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2480\n",
      "Epoch 80/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2500\n",
      "Epoch 81/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2529\n",
      "Epoch 82/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2480\n",
      "Epoch 83/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2441\n",
      "Epoch 84/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2490\n",
      "Epoch 85/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 86/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2607\n",
      "Epoch 87/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2480\n",
      "Epoch 88/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2441\n",
      "Epoch 89/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2461\n",
      "Epoch 90/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 91/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2422\n",
      "Epoch 92/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2539\n",
      "Epoch 93/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2578\n",
      "Epoch 94/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 95/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2490\n",
      "Epoch 96/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 97/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2520\n",
      "Epoch 98/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2422\n",
      "Epoch 99/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2441\n",
      "Epoch 100/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 15450.2422\n"
     ]
    }
   ],
   "source": [
    "# CELL HERE\n",
    "# Defining the model\n",
    "\n",
    "#input_shape = (100, 10)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape = (10,)),  # 8 input features\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')   # Output layer with 5 nodes (one for each player type)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the neural network model for position prediction\n",
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(10,)),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')  # Predict a score between 0 and 1\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Create a model for each position\n",
    "models = {i: create_model() for i in range(1, 6)}\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "selected_features = scaler.fit_transform(selected_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']])\n",
    "\n",
    "# Train a model for each position using the ideal values as targets\n",
    "for i in range(1, 6):\n",
    "    if i == 1:\n",
    "        target = (selected_df['ast']*0.8 + selected_df['gp']*0.2) / TARGET_POINT_GUARD_VALUE\n",
    "    elif i == 2:\n",
    "        target = (selected_df['pts']*0.8 + selected_df['ts_pct']*0.2) / TARGET_SHOOTING_GUARD_VALUE\n",
    "    elif i == 3:\n",
    "        target = (selected_df['ast_pct']*0.3 + selected_df['usg_pct']*0.7) / TARGET_SMALL_FORWARD_VALUE\n",
    "    elif i == 4:\n",
    "        target = (selected_df['net_rating']*0.6 + selected_df['oreb_pct']*0.4) / TARGET_FORWARD_VALUE\n",
    "    elif i == 5:\n",
    "        target = (selected_df['player_height']*0.5 + selected_df['player_weight']*0.5) / TARGET_CENTER_VALUE\n",
    "    models[i].fit(selected_features, target, epochs=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Optimal Team:\n",
      "Position 1: Lance Stephenson\n",
      "Position 2: Lance Stephenson\n",
      "Position 3: Karl-Anthony Towns\n",
      "Position 4: D.J. Augustin\n",
      "Position 5: Lance Stephenson\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'optimal_team = {}\\nfor i in range(1, 6):\\n    scores = models[i].predict(selected_features).flatten()\\n    best_player_idx = scores.argmax()\\n    optimal_team[i] = selected_df.iloc[best_player_idx].name\\n    # Remove this player so they aren\\'t selected again\\n    selected_features = np.delete(selected_features, best_player_idx, axis=0)\\n\\nprint(\"Optimal Team:\")\\nfor pos, player_idx in optimal_team.items():\\n    player_name = df.loc[df.index == player_idx, \\'player_name\\'].values[0]\\n    print(f\"Position {pos}: {player_name}\")'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate each player for each position and select the optimal player\n",
    "optimal_team = {}\n",
    "for i in range(1, 6):\n",
    "    scores = models[i].predict(selected_features).flatten()\n",
    "    best_player_idx = scores.argmax()\n",
    "    optimal_team[i] = selected_df.iloc[best_player_idx].name\n",
    "    # Remove this player so they aren't selected again\n",
    "    selected_features = np.delete(selected_features, best_player_idx, axis=0)\n",
    "\n",
    "print(\"Optimal Team:\")\n",
    "for pos, player_idx in optimal_team.items():\n",
    "    player_name = df.loc[df.index == player_idx, 'player_name'].values[0]\n",
    "    print(f\"Position {pos}: {player_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "382/382 [==============================] - 2s 3ms/step - loss: 3137.5344\n",
      "Epoch 2/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.8215\n",
      "Epoch 3/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.8206\n",
      "Epoch 4/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.8215\n",
      "Epoch 5/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.8220\n",
      "Epoch 6/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.8215\n",
      "Epoch 7/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.8220\n",
      "Epoch 8/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.8210\n",
      "Epoch 9/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.5886\n",
      "Epoch 10/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.4009\n",
      "Epoch 11/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3994\n",
      "Epoch 12/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3992\n",
      "Epoch 13/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3994\n",
      "Epoch 14/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.4004\n",
      "Epoch 15/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3989\n",
      "Epoch 16/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.4014\n",
      "Epoch 17/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3992\n",
      "Epoch 18/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.4009\n",
      "Epoch 19/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 20/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3992\n",
      "Epoch 21/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 22/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3962\n",
      "Epoch 23/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3982\n",
      "Epoch 24/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3992\n",
      "Epoch 25/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.4011\n",
      "Epoch 26/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.4004\n",
      "Epoch 27/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3989\n",
      "Epoch 28/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3989\n",
      "Epoch 29/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3989\n",
      "Epoch 30/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 31/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 32/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3970\n",
      "Epoch 33/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 34/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3982\n",
      "Epoch 35/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3979\n",
      "Epoch 36/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3992\n",
      "Epoch 37/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 38/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3984\n",
      "Epoch 39/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3992\n",
      "Epoch 40/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 41/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 42/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 43/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3982\n",
      "Epoch 44/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3999\n",
      "Epoch 45/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3960\n",
      "Epoch 46/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 47/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3979\n",
      "Epoch 48/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 49/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3979\n",
      "Epoch 50/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3982\n",
      "Epoch 51/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3982\n",
      "Epoch 52/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3994\n",
      "Epoch 53/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3989\n",
      "Epoch 54/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3979\n",
      "Epoch 55/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3982\n",
      "Epoch 56/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3972\n",
      "Epoch 57/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 58/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 59/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 60/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3972\n",
      "Epoch 61/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3979\n",
      "Epoch 62/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3994\n",
      "Epoch 63/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3984\n",
      "Epoch 64/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 65/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 66/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 67/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3972\n",
      "Epoch 68/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 69/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3979\n",
      "Epoch 70/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3984\n",
      "Epoch 71/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3979\n",
      "Epoch 72/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3970\n",
      "Epoch 73/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3994\n",
      "Epoch 74/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3970\n",
      "Epoch 75/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3970\n",
      "Epoch 76/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3989\n",
      "Epoch 77/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3979\n",
      "Epoch 78/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 79/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3994\n",
      "Epoch 80/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 81/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3989\n",
      "Epoch 82/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3970\n",
      "Epoch 83/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.4004\n",
      "Epoch 84/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3982\n",
      "Epoch 85/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3992\n",
      "Epoch 86/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 87/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 88/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3972\n",
      "Epoch 89/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 90/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3982\n",
      "Epoch 91/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.4001\n",
      "Epoch 92/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3979\n",
      "Epoch 93/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3972\n",
      "Epoch 94/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3989\n",
      "Epoch 95/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3955\n",
      "Epoch 96/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3984\n",
      "Epoch 97/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3994\n",
      "Epoch 98/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3975\n",
      "Epoch 99/100\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3136.3965\n",
      "Epoch 100/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 3136.3970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e6ef20b1d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df, val_df = train_test_split(selected_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract the features and labels for training and validation datasets\n",
    "X_train = train_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']].values\n",
    "y_train = train_df[['position']].values.ravel()\n",
    "\n",
    "X_val = val_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']].values\n",
    "y_val = val_df[['position']].values.ravel()\n",
    "\n",
    "# Apply normalization\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n",
      "Optimal Team:\n",
      "Position 1: Lance Stephenson\n",
      "Position 2: Lance Stephenson\n",
      "Position 3: Karl-Anthony Towns\n",
      "Position 4: Patrick McCaw\n",
      "Position 5: Lance Stephenson\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "predictions = model.predict(X_val)\n",
    "predicted_positions = [tf.argmax(pred).numpy() + 1 for pred in predictions]\n",
    "\n",
    "# Create a DataFrame for results\n",
    "results_df = pd.DataFrame({\n",
    "    'Player Index': val_df.index,\n",
    "    'True Position': y_val,\n",
    "    'Predicted Position': predicted_positions\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
