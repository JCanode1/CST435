{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network: NBA Player Dataset Team Optimazitation\n",
    "\n",
    "## Team\n",
    "\n",
    "Gabriel Aracena\n",
    "Joshua Canode\n",
    "Aaron Galicia\n",
    "\n",
    "### Project Description\n",
    "\n",
    "Select a pool of 100 players from the data set, within a 5-year window.\n",
    "Define \"optimal team\" based on your decision of the player characteristics necessary to build a team. For example, if all 5 players are 3-point shooters, the team will miss defenders, which will make it unbalanced.\n",
    "Your task is to identify the optimal team of 5 players from that pool.\n",
    "Examine the multilayer neural network MLP architecture depicted in the \"CST-435 An Artificial Neural Network Model Image.\"\n",
    "Build a deep artificial neural network MLP to include the following: a) 1 input layer, b) as many hidden layers as you deem necessary, and c) an output layer fully connected to the hidden layers.\n",
    "Explain your architecture and how the basketball player characteristics are used as inputs.\n",
    "Activate the MLP by performing the following steps:\n",
    "\n",
    "Starting at the input layer, forward propagate the patterns of the training data through the network to generate an output.\n",
    "Based on the network's output, calculate the error that we want to minimize using a cost function that we will describe later.\n",
    "Backpropagate the error, find its derivative with respect to each weight in the network, and update the model.\n",
    "Repeat steps 1 through 3 for multiple epochs and learn the weights of the MLP.\n",
    "Use forward propagation to calculate the network output and apply a threshold function to obtain the predicted class labels in the one-hot representation.\n",
    "Interpret the output of your MLP in the context of selecting an optimal basketball team.\n",
    "\n",
    "## Abstract\n",
    "\n",
    "The objective is to use a deep artificial neural network (ANN) to determine an optimal team composition from a pool of basketball players. Given player characteristics, we want to identify the best five players that result in a balanced team.\n",
    "\n",
    "### Data Preparation:\n",
    "\n",
    "* Load the NBA Players Dataset.\n",
    "* Filter to get a pool of 100 players from a random 5-year window.\n",
    "* Normalize/Standardize player characteristics.\n",
    "\n",
    "### ANN Model Building:\n",
    "\n",
    "* Design a Multi-layer Perceptron (MLP) based on the architecture of the CST-435 An Artificial Neural Network Model Image (see below)\n",
    "* Define layers: Input layer, Hidden layers, and Output layer.\n",
    "* Determine the appropriate activation function, optimizer, and loss function for the MLP.\n",
    "\n",
    "![ANNModel](ANNModel.png)\n",
    "\n",
    "### Training the ANN:\n",
    "\n",
    "* Forward propagation: Use player characteristics to propagate input data through the network and generate an output.\n",
    "* Calculate the error using a predefined cost function.\n",
    "* Backpropagate the error to update model weights.\n",
    "* Repeat the above steps for several epochs.\n",
    "\n",
    "### Evaluation and Team Selection:\n",
    "\n",
    "* Use forward propagation on the trained ANN to predict player effectiveness or class labels.\n",
    "* Apply a threshold function to these predictions.\n",
    "* Select the top five players that meet the optimal team criteria.\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "* Input Layer: This layer will have neurons equal to the number of player characteristics we're considering (e.g. points, assists, offensive rebounds, defensive rebounds,etc.).\n",
    "* Hidden Layers: Multiple hidden layers can be used to capture intricate patterns and relationships. We initially thought we would do 5 hidden layers, one for each position,  but we decided to stick with only a single layer for simplicity and might change that later. \n",
    "* Output Layer: This layer can have neurons equal to the number of classes or roles in the team we're predicting for (e.g., point guard, shooting guard, center, etc.). Each neuron will give the likelihood of a player fitting that role.\n",
    "\n",
    "## Activation and Threshold Function\n",
    "\n",
    "During forward propagation, each neuron processes input data and transmits it to the next layer. An activation function is applied to this data. For this model, we can use the ReLU (Rectified Linear Unit) activation function for hidden layers due to its computational efficiency and the ability to handle non-linearities. The softmax function might be applied to the output layer as it provides a probability distribution.\n",
    "\n",
    "After obtaining the output, a threshold function is applied to convert continuous values into distinct class labels. In this case, it can be the player's most likely role in the team.\n",
    "\n",
    "## Interpretation and Conclusion\n",
    "\n",
    "The final output provides us with a categorization of each player in our pool. By examining the predicted class labels and the associated probabilities, we can:\n",
    "* Identify which role or position each player is most suited for.\n",
    "* Select the top players for each role to form our optimal team.\n",
    "\n",
    "We are going to define target values for each position and use hope to use that in the end of each training to classify if the output team was good or not. \n",
    "\n",
    "It's worth noting that the \"optimal\" team is contingent on the data provided and the neural network's training. For better results, the model should be regularly trained with updated data, and other external factors (like team chemistry and current form) should also be considered in real-world scenarios. For our optimal team we defined some weights based on each player position that will take into account the 2 most important stats for each position according to our criteria. See Definig player types bellow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defining Player types    \n",
    "\n",
    "After research, the teams will be made up of different positions: center, foward, small forward, guard, and point guard. These positions requre different specialties. Making use of the statistics provided by the CSV, we have chosen two weights that control what factors are important to the role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n5 center\\n\\theight = 0.5\\n\\tweight = 0.5\\n\\n4 forward\\n\\tnet_rating = 0.6\\n\\treb = 0.4\\n\\n3 small forward\\n\\tast_pct = 0.3\\n\\tusg_pct = 0.7\\n\\n2 guard\\n\\tpts = 0.8\\n\\tts_pct = 0.2\\n\\n1 point guard\\n\\tast = 0.8\\n\\tgp = 0.2\\n\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "5 center\n",
    "\theight = 0.5\n",
    "\tweight = 0.5\n",
    "\n",
    "4 forward\n",
    "\tnet_rating = 0.6\n",
    "\treb = 0.4\n",
    "\n",
    "3 small forward\n",
    "\tast_pct = 0.3\n",
    "\tusg_pct = 0.7\n",
    "\n",
    "2 guard\n",
    "\tpts = 0.8\n",
    "\tts_pct = 0.2\n",
    "\n",
    "1 point guard\n",
    "\tast = 0.8\n",
    "\tgp = 0.2\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the DataFrame:\n",
      "   Unnamed: 0        player_name team_abbreviation   age  player_height  \\\n",
      "0           0      Dennis Rodman               CHI  36.0         198.12   \n",
      "1           1  Dwayne Schintzius               LAC  28.0         215.90   \n",
      "2           2       Earl Cureton               TOR  39.0         205.74   \n",
      "3           3        Ed O'Bannon               DAL  24.0         203.20   \n",
      "4           4        Ed Pinckney               MIA  34.0         205.74   \n",
      "\n",
      "   player_weight                      college country draft_year draft_round  \\\n",
      "0      99.790240  Southeastern Oklahoma State     USA       1986           2   \n",
      "1     117.933920                      Florida     USA       1990           1   \n",
      "2      95.254320                Detroit Mercy     USA       1979           3   \n",
      "3     100.697424                         UCLA     USA       1995           1   \n",
      "4     108.862080                    Villanova     USA       1985           1   \n",
      "\n",
      "   ...  pts   reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
      "0  ...  5.7  16.1  3.1        16.1     0.186     0.323    0.100   0.479   \n",
      "1  ...  2.3   1.5  0.3        12.3     0.078     0.151    0.175   0.430   \n",
      "2  ...  0.8   1.0  0.4        -2.1     0.105     0.102    0.103   0.376   \n",
      "3  ...  3.7   2.3  0.6        -8.7     0.060     0.149    0.167   0.399   \n",
      "4  ...  2.4   2.4  0.2       -11.2     0.109     0.179    0.127   0.611   \n",
      "\n",
      "   ast_pct   season  \n",
      "0    0.113  1996-97  \n",
      "1    0.048  1996-97  \n",
      "2    0.148  1996-97  \n",
      "3    0.077  1996-97  \n",
      "4    0.040  1996-97  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Tail of the DataFrame:\n",
      "       Unnamed: 0      player_name team_abbreviation   age  player_height  \\\n",
      "12300       12300  Markieff Morris               MIA  32.0         205.74   \n",
      "12301       12301   Markelle Fultz               ORL  24.0         193.04   \n",
      "12302       12302     Marcus Smart               BOS  28.0         193.04   \n",
      "12303       12303   Marcus Garrett               MIA  23.0         195.58   \n",
      "12304       12304     Micah Potter               DET  24.0         208.28   \n",
      "\n",
      "       player_weight         college country draft_year draft_round  ...  \\\n",
      "12300     111.130040          Kansas     USA       2011           1  ...   \n",
      "12301      94.800728      Washington     USA       2017           1  ...   \n",
      "12302      99.790240  Oklahoma State     USA       2014           1  ...   \n",
      "12303      92.986360          Kansas     USA  Undrafted   Undrafted  ...   \n",
      "12304     112.490816       Wisconsin     USA  Undrafted   Undrafted  ...   \n",
      "\n",
      "        pts  reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
      "12300   7.6  2.6  1.4         4.5     0.059     0.089    0.197   0.547   \n",
      "12301  10.8  2.7  5.5        -5.3     0.010     0.116    0.265   0.517   \n",
      "12302  12.1  3.8  5.9         9.3     0.018     0.093    0.179   0.540   \n",
      "12303   1.1  1.9  0.6         5.8     0.072     0.108    0.086   0.280   \n",
      "12304   4.0  3.0  0.0       -56.4     0.095     0.125    0.148   0.505   \n",
      "\n",
      "       ast_pct   season  \n",
      "12300    0.116  2021-22  \n",
      "12301    0.448  2021-22  \n",
      "12302    0.245  2021-22  \n",
      "12303    0.069  2021-22  \n",
      "12304    0.000  2021-22  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the file path\n",
    "file_path = \"all_seasons.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the head (first few rows) of the DataFrame\n",
    "print(\"Head of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the tail (last few rows) of the DataFrame\n",
    "print(\"\\nTail of the DataFrame:\")\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining target stats based on player types\n",
    "\n",
    "The weights decided above will be used before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.36\n",
      "29.180000000000003\n",
      "1.0\n",
      "180.4\n",
      "204.00124799999998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def calculateTargetValue(position, stat1, stat2):\n",
    "    # Point Guard: ast = 0.8 gp = 0.2\n",
    "    # Shooting Guard: pts = 0.8 ts_pct = 0.2\n",
    "    if (position == 1 or position == 2):\n",
    "        weightedValue = ((stat1) * 0.8 + (stat2) * 0.2 )\n",
    "        return weightedValue\n",
    "    \n",
    "    # Small Forward: ast_pct = 0.3 usg_pct = 0.7\n",
    "    elif (position == 3):\n",
    "        weightedValue = ((stat1) * 0.3 + (stat2) * 0.7 )\n",
    "        return weightedValue\n",
    "    # Forward: net_rating = 0.6 reb = 0.4\n",
    "    elif (position == 4):\n",
    "        weightedValue = ((stat1) * 0.6 + (stat2) * 0.4 )\n",
    "        return weightedValue\n",
    "    # Center: height = 0.5 weight = 0.5\n",
    "    elif (position == 5):\n",
    "        weightedValue = ((stat1) * 0.6 + (stat2) * 0.4 )\n",
    "        return weightedValue\n",
    "\n",
    "MAXIMUM_ASSIST = max(df['ast'])\n",
    "MAXIMUM_GP = max(df['gp'])\n",
    "MAXIMUM_PTS = max(df['pts'])\n",
    "MAXIMUM_SHOOTING_RATE = max(df['ts_pct'])\n",
    "MAXIMUM_ASSIST_PCTG = max(df['ast_pct'])\n",
    "MAXIMUM_USG_PCT = max(df['usg_pct']) \n",
    "MAXIMUM_NET_RATING = max(df['net_rating'])\n",
    "MAXIMUM_REB = max(df['oreb_pct'])\n",
    "MAXIMUM_HEIGHT = max(df['player_height']) \n",
    "MAXIMUM_WEIGHT = max(df['player_weight']) \n",
    "\n",
    "# The target stats will be 80% of the maximum value (it will be really hard to get 100% all the time since we are going to only use 100 players out of the whole dataset)\n",
    "TARGET_POINT_GUARD_VALUE = calculateTargetValue(1, MAXIMUM_ASSIST, MAXIMUM_GP)\n",
    "TARGET_SHOOTING_GUARD_VALUE = calculateTargetValue(2, MAXIMUM_PTS, MAXIMUM_SHOOTING_RATE)\n",
    "TARGET_SMALL_FORWARD_VALUE = calculateTargetValue(3, MAXIMUM_ASSIST_PCTG, MAXIMUM_USG_PCT)\n",
    "TARGET_FORWARD_VALUE = calculateTargetValue(4, MAXIMUM_NET_RATING, MAXIMUM_REB)\n",
    "TARGET_CENTER_VALUE = calculateTargetValue(5, MAXIMUM_HEIGHT, MAXIMUM_WEIGHT)\n",
    "\n",
    "print(TARGET_POINT_GUARD_VALUE)\n",
    "print(TARGET_SHOOTING_GUARD_VALUE)\n",
    "print(TARGET_SMALL_FORWARD_VALUE)\n",
    "print(TARGET_FORWARD_VALUE)\n",
    "print(TARGET_CENTER_VALUE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0        player_name team_abbreviation   age  player_height  \\\n",
      "9723         9723        Ben Simmons               PHI  21.0         208.28   \n",
      "8113         8113    Jorge Gutierrez               MIL  26.0         190.50   \n",
      "9911         9911       Marcus Smart               BOS  24.0         193.04   \n",
      "8166         8166       Luke Babbitt               NOP  26.0         205.74   \n",
      "7872         7872      Jason Collins               BKN  35.0         213.36   \n",
      "...           ...                ...               ...   ...            ...   \n",
      "10429       10429        D.J. Wilson               MIL  23.0         208.28   \n",
      "9344         9344     Chasson Randle               NYK  24.0         187.96   \n",
      "9157         9157  Richard Jefferson               CLE  37.0         200.66   \n",
      "8485         8485    Brendan Haywood               CLE  35.0         213.36   \n",
      "8479         8479      Arinze Onuaku               MIN  27.0         205.74   \n",
      "\n",
      "       player_weight              college    country  draft_year draft_round  \\\n",
      "9723      104.326160      Louisiana State  Australia        2017           1   \n",
      "8113       88.450440  California-Berkeley     Mexico        2014   Undrafted   \n",
      "9911       99.790240       Oklahoma State        USA        2017           1   \n",
      "8166      102.058200               Nevada        USA        2014           1   \n",
      "7872      115.665960             Stanford        USA        2013           1   \n",
      "...              ...                  ...        ...         ...         ...   \n",
      "10429     104.779752             Michigan        USA        2018           1   \n",
      "9344       83.914520             Stanford        USA        2016   Undrafted   \n",
      "9157      105.686936              Arizona        USA        2016           1   \n",
      "8485      119.294696       North Carolina        USA        2014           1   \n",
      "8479      124.737800             Syracuse        USA        2014   Undrafted   \n",
      "\n",
      "       ...   pts  reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
      "9723   ...  15.8  8.1  8.2         6.6     0.053     0.171    0.219   0.557   \n",
      "8113   ...   2.7  1.3  1.1        -7.0     0.032     0.119    0.151   0.567   \n",
      "9911   ...  10.2  3.5  4.8         6.2     0.026     0.085    0.187   0.479   \n",
      "8166   ...   4.1  1.8  0.4        -5.1     0.017     0.131    0.125   0.639   \n",
      "7872   ...   1.1  0.9  0.2        -9.2     0.048     0.086    0.089   0.485   \n",
      "...    ...   ...  ...  ...         ...       ...       ...      ...     ...   \n",
      "10429  ...   5.8  4.6  1.1         4.9     0.047     0.174    0.141   0.515   \n",
      "9344   ...   5.3  1.2  1.3        -3.4     0.022     0.097    0.197   0.586   \n",
      "9157   ...   5.7  2.6  1.0         3.4     0.020     0.115    0.123   0.574   \n",
      "8485   ...   1.6  1.3  0.1       -21.3     0.056     0.192    0.181   0.490   \n",
      "8479   ...   4.5  3.5  0.7        -9.7     0.115     0.212    0.125   0.771   \n",
      "\n",
      "       ast_pct   season  \n",
      "9723     0.362  2017-18  \n",
      "8113     0.212  2014-15  \n",
      "9911     0.234  2017-18  \n",
      "8166     0.044  2014-15  \n",
      "7872     0.034  2013-14  \n",
      "...        ...      ...  \n",
      "10429    0.080  2018-19  \n",
      "9344     0.173  2016-17  \n",
      "9157     0.068  2016-17  \n",
      "8485     0.032  2014-15  \n",
      "8479     0.089  2014-15  \n",
      "\n",
      "[100 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "df['draft_year'] = df['season'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# Define the target year and the window size\n",
    "enough_players = False\n",
    "window_size = 5\n",
    "while not enough_players:\n",
    "    target_year = random.randint(min(df['draft_year']), max(df['draft_year']))\n",
    "    start_year = target_year - window_size\n",
    "    end_year = target_year\n",
    "    filtered_df = df[(df['draft_year'] >= start_year) & (df['draft_year'] <= end_year)]\n",
    "    \n",
    "    if len(filtered_df) >= 100:\n",
    "        enough_players = True\n",
    "        selected_players = random.sample(range(len(filtered_df)), 100)\n",
    "        test_df = filtered_df.iloc[selected_players]\n",
    "        '''random.seed(42)\n",
    "        selected_players = random.sample(range(len(filtered_df)), 100)\n",
    "        selected_df = filtered_df.iloc[selected_players]\n",
    "        '''\n",
    "        print(test_df)\n",
    "\n",
    "# Split the rest of the data (excluding the selected 100 players) for training\n",
    "train_df = df.drop(test_df.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and Training Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 0.0023\n",
      "Epoch 2/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 3.1340e-04\n",
      "Epoch 3/50\n",
      "382/382 [==============================] - 0s 1ms/step - loss: 2.3946e-04\n",
      "Epoch 4/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.8950e-04\n",
      "Epoch 5/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.4503e-04\n",
      "Epoch 6/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1326e-04\n",
      "Epoch 7/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 9.1946e-05\n",
      "Epoch 8/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.7066e-05\n",
      "Epoch 9/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 6.6639e-05\n",
      "Epoch 10/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 5.6875e-05\n",
      "Epoch 11/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.8254e-05\n",
      "Epoch 12/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 4.2595e-05\n",
      "Epoch 13/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.8962e-05\n",
      "Epoch 14/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.6870e-05\n",
      "Epoch 15/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.1342e-05\n",
      "Epoch 16/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.8260e-05\n",
      "Epoch 17/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.5940e-05\n",
      "Epoch 18/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 2.3802e-05\n",
      "Epoch 19/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.1530e-05\n",
      "Epoch 20/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 1.9202e-05\n",
      "Epoch 21/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.8164e-05\n",
      "Epoch 22/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.6362e-05\n",
      "Epoch 23/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.4635e-05\n",
      "Epoch 24/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.3127e-05\n",
      "Epoch 25/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1889e-05\n",
      "Epoch 26/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2166e-05\n",
      "Epoch 27/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.0772e-05\n",
      "Epoch 28/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.3093e-06\n",
      "Epoch 29/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.3603e-06\n",
      "Epoch 30/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.6014e-06\n",
      "Epoch 31/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 7.2524e-06\n",
      "Epoch 32/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.3190e-06\n",
      "Epoch 33/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.1436e-06\n",
      "Epoch 34/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.1114e-06\n",
      "Epoch 35/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 5.3317e-06\n",
      "Epoch 36/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.7729e-06\n",
      "Epoch 37/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 5.2977e-06\n",
      "Epoch 38/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 4.7726e-06\n",
      "Epoch 39/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.8899e-06\n",
      "Epoch 40/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.8573e-06\n",
      "Epoch 41/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.9545e-06\n",
      "Epoch 42/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.0315e-06\n",
      "Epoch 43/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 3.6821e-06\n",
      "Epoch 44/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.6129e-06\n",
      "Epoch 45/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.2900e-06\n",
      "Epoch 46/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.6019e-06\n",
      "Epoch 47/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.3489e-06\n",
      "Epoch 48/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 2.9738e-06\n",
      "Epoch 49/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.5572e-06\n",
      "Epoch 50/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.5978e-06\n",
      "Epoch 1/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 0.0074\n",
      "Epoch 2/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 4.6485e-04\n",
      "Epoch 3/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.2689e-04\n",
      "Epoch 4/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 1.4833e-04\n",
      "Epoch 5/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 1.2056e-04\n",
      "Epoch 6/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.0424e-04\n",
      "Epoch 7/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.3043e-05\n",
      "Epoch 8/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.4905e-05\n",
      "Epoch 9/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.7824e-05\n",
      "Epoch 10/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.2192e-05\n",
      "Epoch 11/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.6024e-05\n",
      "Epoch 12/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 5.9093e-05\n",
      "Epoch 13/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.4357e-05\n",
      "Epoch 14/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 4.7604e-05\n",
      "Epoch 15/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.4868e-05\n",
      "Epoch 16/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 3.7370e-05\n",
      "Epoch 17/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.2663e-05\n",
      "Epoch 18/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.0345e-05\n",
      "Epoch 19/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 2.7501e-05\n",
      "Epoch 20/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 2.6329e-05\n",
      "Epoch 21/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.2847e-05\n",
      "Epoch 22/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.3887e-05\n",
      "Epoch 23/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.1565e-05\n",
      "Epoch 24/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.0116e-05\n",
      "Epoch 25/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.7442e-05\n",
      "Epoch 26/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.6840e-05\n",
      "Epoch 27/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.7608e-05\n",
      "Epoch 28/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.5436e-05\n",
      "Epoch 29/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.5859e-05\n",
      "Epoch 30/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.4065e-05\n",
      "Epoch 31/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.5523e-05\n",
      "Epoch 32/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2036e-05\n",
      "Epoch 33/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.5170e-05\n",
      "Epoch 34/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2705e-05\n",
      "Epoch 35/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1427e-05\n",
      "Epoch 36/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2785e-05\n",
      "Epoch 37/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.0233e-05\n",
      "Epoch 38/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.4787e-06\n",
      "Epoch 39/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.0464e-05\n",
      "Epoch 40/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.5947e-06\n",
      "Epoch 41/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.3757e-06\n",
      "Epoch 42/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.0404e-06\n",
      "Epoch 43/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.6899e-06\n",
      "Epoch 44/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 6.2372e-06\n",
      "Epoch 45/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.2971e-06\n",
      "Epoch 46/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.4910e-06\n",
      "Epoch 47/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.4586e-06\n",
      "Epoch 48/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.0187e-06\n",
      "Epoch 49/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.3244e-06\n",
      "Epoch 50/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.6271e-06\n",
      "Epoch 1/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0104\n",
      "Epoch 2/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.6785e-04\n",
      "Epoch 3/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.3552e-04\n",
      "Epoch 4/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.3940e-04\n",
      "Epoch 5/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 7.3582e-05\n",
      "Epoch 6/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.2053e-05\n",
      "Epoch 7/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.3678e-05\n",
      "Epoch 8/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.5355e-05\n",
      "Epoch 9/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 3.6162e-05\n",
      "Epoch 10/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.2459e-05\n",
      "Epoch 11/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.5327e-05\n",
      "Epoch 12/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 2.2479e-05\n",
      "Epoch 13/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.1163e-05\n",
      "Epoch 14/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.9535e-05\n",
      "Epoch 15/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7661e-05\n",
      "Epoch 16/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.7921e-05\n",
      "Epoch 17/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.5584e-05\n",
      "Epoch 18/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 3.7331e-05\n",
      "Epoch 19/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.8068e-05\n",
      "Epoch 20/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.0303e-05\n",
      "Epoch 21/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.7425e-05\n",
      "Epoch 22/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.0511e-05\n",
      "Epoch 23/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.5606e-05\n",
      "Epoch 24/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2588e-05\n",
      "Epoch 25/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.5412e-05\n",
      "Epoch 26/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.8462e-05\n",
      "Epoch 27/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.0775e-06\n",
      "Epoch 28/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.4612e-06\n",
      "Epoch 29/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.6459e-06\n",
      "Epoch 30/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.7527e-06\n",
      "Epoch 31/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.0450e-05\n",
      "Epoch 32/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 1.5955e-05\n",
      "Epoch 33/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.5334e-06\n",
      "Epoch 34/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.8819e-05\n",
      "Epoch 35/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.0509e-06\n",
      "Epoch 36/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2588e-05\n",
      "Epoch 37/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1922e-05\n",
      "Epoch 38/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.2773e-06\n",
      "Epoch 39/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1136e-05\n",
      "Epoch 40/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.3052e-05\n",
      "Epoch 41/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.7315e-06\n",
      "Epoch 42/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.2511e-06\n",
      "Epoch 43/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.0426e-06\n",
      "Epoch 44/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.5154e-06\n",
      "Epoch 45/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.5646e-05\n",
      "Epoch 46/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.0794e-06\n",
      "Epoch 47/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.9639e-06\n",
      "Epoch 48/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.9471e-06\n",
      "Epoch 49/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.9513e-06\n",
      "Epoch 50/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 7.8675e-06\n",
      "Epoch 1/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0171\n",
      "Epoch 2/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0023\n",
      "Epoch 3/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0020\n",
      "Epoch 4/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0019\n",
      "Epoch 5/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0017\n",
      "Epoch 6/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0016\n",
      "Epoch 7/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0016\n",
      "Epoch 8/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0015\n",
      "Epoch 9/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0015\n",
      "Epoch 10/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0015\n",
      "Epoch 11/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0014\n",
      "Epoch 12/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0014\n",
      "Epoch 13/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0014\n",
      "Epoch 14/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0014\n",
      "Epoch 15/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0014\n",
      "Epoch 16/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0014\n",
      "Epoch 17/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 18/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 19/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 20/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 21/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 22/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 23/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 24/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 25/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 26/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 27/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 28/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 29/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 30/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 31/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 32/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 33/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 34/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 35/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 36/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 37/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 38/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 39/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 40/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 41/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 42/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 43/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 44/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 45/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 46/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 47/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 48/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 49/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 50/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0013\n",
      "Epoch 1/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 0.0041\n",
      "Epoch 2/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 3.7911e-04\n",
      "Epoch 3/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1438e-04\n",
      "Epoch 4/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.9943e-05\n",
      "Epoch 5/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.5554e-05\n",
      "Epoch 6/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.6211e-05\n",
      "Epoch 7/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.1985e-05\n",
      "Epoch 8/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.8637e-05\n",
      "Epoch 9/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.4364e-05\n",
      "Epoch 10/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.1666e-05\n",
      "Epoch 11/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.1106e-05\n",
      "Epoch 12/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.5847e-05\n",
      "Epoch 13/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 1.7831e-05\n",
      "Epoch 14/50\n",
      "382/382 [==============================] - 1s 1ms/step - loss: 1.4033e-05\n",
      "Epoch 15/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2426e-05\n",
      "Epoch 16/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.6255e-05\n",
      "Epoch 17/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.2266e-05\n",
      "Epoch 18/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1362e-05\n",
      "Epoch 19/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.0307e-05\n",
      "Epoch 20/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.7112e-06\n",
      "Epoch 21/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.7662e-06\n",
      "Epoch 22/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.9336e-06\n",
      "Epoch 23/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 9.1230e-06\n",
      "Epoch 24/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.3966e-05\n",
      "Epoch 25/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.6933e-06\n",
      "Epoch 26/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 8.1434e-06\n",
      "Epoch 27/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.2164e-06\n",
      "Epoch 28/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.2523e-06\n",
      "Epoch 29/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.1034e-05\n",
      "Epoch 30/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.1818e-06\n",
      "Epoch 31/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.2393e-06\n",
      "Epoch 32/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.0466e-06\n",
      "Epoch 33/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 5.9904e-06\n",
      "Epoch 34/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.3178e-06\n",
      "Epoch 35/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.8726e-06\n",
      "Epoch 36/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7674e-06\n",
      "Epoch 37/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.4884e-06\n",
      "Epoch 38/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 6.4977e-06\n",
      "Epoch 39/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.2846e-06\n",
      "Epoch 40/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.2788e-06\n",
      "Epoch 41/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.3492e-06\n",
      "Epoch 42/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.3656e-06\n",
      "Epoch 43/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.1828e-06\n",
      "Epoch 44/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.9088e-06\n",
      "Epoch 45/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.4551e-06\n",
      "Epoch 46/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7468e-06\n",
      "Epoch 47/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.5799e-06\n",
      "Epoch 48/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.0678e-06\n",
      "Epoch 49/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 1.4502e-06\n",
      "Epoch 50/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.4319e-06\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "#input_shape = (100, 10)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape = (10,)),  # 8 input features\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')   # Output layer with 5 nodes (one for each player type)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the neural network model for position prediction\n",
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(10,)),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')  # Predict a score between 0 and 1\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Create a model for each position\n",
    "models = {i: create_model() for i in range(1, 6)}\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "selected_features = scaler.fit_transform(train_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']])\n",
    "names_df = train_df['player_name'] # Player Names\n",
    "\n",
    "# Train a model for each position using the ideal values as targets\n",
    "for i in range(1, 6):\n",
    "    if i == 1:\n",
    "        target = (train_df['ast']*0.8 + train_df['gp']*0.2) / TARGET_POINT_GUARD_VALUE\n",
    "    elif i == 2:\n",
    "        target = (train_df['pts']*0.8 + train_df['ts_pct']*0.2) / TARGET_SHOOTING_GUARD_VALUE\n",
    "    elif i == 3:\n",
    "        target = (train_df['ast_pct']*0.3 + train_df['usg_pct']*0.7) / TARGET_SMALL_FORWARD_VALUE\n",
    "    elif i == 4:\n",
    "        target = (train_df['net_rating']*0.6 + train_df['oreb_pct']*0.4) / TARGET_FORWARD_VALUE\n",
    "    elif i == 5:\n",
    "        target = (train_df['player_height']*0.5 + train_df['player_weight']*0.5) / TARGET_CENTER_VALUE\n",
    "    models[i].fit(selected_features, target, epochs=50)\n",
    "\n",
    "# Evaluate each player in the test set (100 players) for each position and select the optimal player\n",
    "X_test = scaler.transform(test_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Optimal Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 1s 2ms/step\n",
      "382/382 [==============================] - 1s 1ms/step\n",
      "382/382 [==============================] - 1s 2ms/step\n",
      "382/382 [==============================] - 1s 2ms/step\n",
      "382/382 [==============================] - 1s 2ms/step\n",
      "Optimal Team:\n",
      "Position 1: Mark Jackson\n",
      "Position 2: Jamal Murray\n",
      "Position 3: Gerard King\n",
      "Position 4: Bruce Bowen\n",
      "Position 5: Marc Gasol\n"
     ]
    }
   ],
   "source": [
    "optimal_team = {}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    scores = models[i].predict(selected_features).flatten()\n",
    "    best_player_idx = scores.argmax()\n",
    "    for x, y in optimal_team.items():\n",
    "        if names_df.iloc[best_player_idx] == y:\n",
    "            selected_features = np.delete(selected_features, best_player_idx, axis=0)\n",
    "            names_df.drop(best_player_idx)\n",
    "            scores = models[i].predict(selected_features).flatten()\n",
    "            best_player_idx = scores.argmax()\n",
    "            break\n",
    "    optimal_team[i] = names_df.iloc[best_player_idx]\n",
    "    # Remove this player so they aren't selected again\n",
    "    selected_features = np.delete(selected_features, best_player_idx, axis=0)\n",
    "    names_df.drop(best_player_idx)\n",
    "\n",
    "print(\"Optimal Team:\")\n",
    "for pos, player_idx in optimal_team.items():\n",
    "    print(f\"Position {pos}: {player_idx}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above represents the optimal team that the neural network decided. When running the prediction multiple times, the players predicted by the neural network does fluctuate. This could be due to multiple factors. It is likely due to the inherent randomness in some aspects of the code and the network itself. A random time range is chosen with a random 100 players so the players will change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach: 1 ANN 5 Hidden layers\n",
    "\n",
    "Since we were unsure if it is acceptable to do the project with 5 small ANN's for each position, we decided to also do 1 singular ANN with 5 hidden layer. Each Layer will train and adjust the weights for that correspondent position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "382/382 [==============================] - 2s 3ms/step - loss: 0.0042\n",
      "Epoch 2/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.8051e-04\n",
      "Epoch 3/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 4.4124e-04\n",
      "Epoch 4/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.2027e-04\n",
      "Epoch 5/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.1007e-04\n",
      "Epoch 6/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.0456e-04\n",
      "Epoch 7/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.9757e-04\n",
      "Epoch 8/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.9874e-04\n",
      "Epoch 9/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.9480e-04\n",
      "Epoch 10/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.8729e-04\n",
      "Epoch 11/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.8254e-04\n",
      "Epoch 12/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.6966e-04\n",
      "Epoch 13/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.5705e-04\n",
      "Epoch 14/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.5547e-04\n",
      "Epoch 15/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 4.1728e-04\n",
      "Epoch 16/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.7158e-04\n",
      "Epoch 17/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 3.4605e-04\n",
      "Epoch 18/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.9214e-04\n",
      "Epoch 19/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.9336e-04\n",
      "Epoch 20/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.8277e-04\n",
      "Epoch 21/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7346e-04\n",
      "Epoch 22/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7653e-04\n",
      "Epoch 23/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.8324e-04\n",
      "Epoch 24/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.8220e-04\n",
      "Epoch 25/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7703e-04\n",
      "Epoch 26/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6779e-04\n",
      "Epoch 27/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6935e-04\n",
      "Epoch 28/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7234e-04\n",
      "Epoch 29/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6971e-04\n",
      "Epoch 30/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7266e-04\n",
      "Epoch 31/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7880e-04\n",
      "Epoch 32/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.8086e-04\n",
      "Epoch 33/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.8869e-04\n",
      "Epoch 34/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6929e-04\n",
      "Epoch 35/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7459e-04\n",
      "Epoch 36/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6912e-04\n",
      "Epoch 37/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6940e-04\n",
      "Epoch 38/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6605e-04\n",
      "Epoch 39/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7298e-04\n",
      "Epoch 40/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7250e-04\n",
      "Epoch 41/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6860e-04\n",
      "Epoch 42/50\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 2.7602e-04\n",
      "Epoch 43/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6904e-04\n",
      "Epoch 44/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.8334e-04\n",
      "Epoch 45/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6584e-04\n",
      "Epoch 46/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6192e-04\n",
      "Epoch 47/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6253e-04\n",
      "Epoch 48/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6386e-04\n",
      "Epoch 49/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.7338e-04\n",
      "Epoch 50/50\n",
      "382/382 [==============================] - 1s 2ms/step - loss: 2.6951e-04\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "Optimal Team:\n",
      "Position 1: Player Name Ben Simmons\n",
      "Position 2: Player Name Nemanja Bjelica\n",
      "Position 3: Player Name Anthony Morrow\n",
      "Position 4: Player Name Aron Baynes\n",
      "Position 5: Player Name Aaron Brooks\n"
     ]
    }
   ],
   "source": [
    "def create_model2():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(10,)),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(5, activation='sigmoid')  # Predict 5 scores (one for each position)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "model2 = create_model2()\n",
    "\n",
    "X_train2 = scaler.fit_transform(train_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']])\n",
    "X_test2 = scaler.transform(test_df[['ast', 'gp', 'pts', 'ts_pct', 'ast_pct', 'usg_pct', 'net_rating', 'oreb_pct', 'player_height', 'player_weight']])\n",
    "\n",
    "# Create training target values for each position\n",
    "Y_train2 = np.vstack([\n",
    "    (train_df['ast']*0.8 + train_df['gp']*0.2) / TARGET_POINT_GUARD_VALUE,\n",
    "    (train_df['pts']*0.8 + train_df['ts_pct']*0.2) / TARGET_SHOOTING_GUARD_VALUE,\n",
    "    (train_df['ast_pct']*0.3 + train_df['usg_pct']*0.7) / TARGET_SMALL_FORWARD_VALUE,\n",
    "    (train_df['net_rating']*0.6 + train_df['oreb_pct']*0.4) / TARGET_FORWARD_VALUE,\n",
    "    (train_df['player_height']*0.5 + train_df['player_weight']*0.5) / TARGET_CENTER_VALUE\n",
    "]).T\n",
    "\n",
    "model2.fit(X_train2, Y_train2, epochs=50)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions2 = model2.predict(X_test2)\n",
    "\n",
    "# Select optimal team\n",
    "optimal_team2 = {}\n",
    "for i in range(5):  # For each position\n",
    "    best_player_idx2 = predictions2[:, i].argmax()\n",
    "    optimal_team2[i + 1] = test_df.iloc[best_player_idx2].name\n",
    "    # Remove this player so they aren't selected again\n",
    "    predictions2 = np.delete(predictions2, best_player_idx2, axis=0)\n",
    "\n",
    "print(\"Optimal Team:\")\n",
    "for pos, player_idx in optimal_team2.items():\n",
    "    player_name = df.loc[df.index == player_idx, 'player_name'].values[0]\n",
    "    print(f\"Position {pos}: Player Name {player_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As you can see both approaches produce different outcomes. However, both of their loss function are extremely low so it is hard to tell which one is the proper one, rather one could say which one they prefer the most. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
